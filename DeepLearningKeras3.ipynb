{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOx66RF7Zc998vpwOmpqpSY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "edbd2a077ce24db899b2e8c68964056f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b830ece7be4464caf0b204849638887",
              "IPY_MODEL_8a9e4301c8864d66aececde9c1bb3340",
              "IPY_MODEL_a6752d168a854a4aaa7a2484263b9c23"
            ],
            "layout": "IPY_MODEL_ffc7f6115ec243c7a5aabc0b3c8eee0e",
            "tabbable": null,
            "tooltip": null
          }
        },
        "9b830ece7be4464caf0b204849638887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_e9edaecea7b047d2923d2807b816a22d",
            "placeholder": "​",
            "style": "IPY_MODEL_1b43093c158d41c99b9c0adc6fdcb52f",
            "tabbable": null,
            "tooltip": null,
            "value": "Downloading diabetes.csv: 100%"
          }
        },
        "8a9e4301c8864d66aececde9c1bb3340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_05732f51858749e9af0e5dd9201bd9f4",
            "max": 23873,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fcf9d309f6374f388dbb442db2a907a5",
            "tabbable": null,
            "tooltip": null,
            "value": 23873
          }
        },
        "a6752d168a854a4aaa7a2484263b9c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_e36106515ae64baca9313ea6a33e05fe",
            "placeholder": "​",
            "style": "IPY_MODEL_ed65a240671c48079465b9425dfcb876",
            "tabbable": null,
            "tooltip": null,
            "value": " 23873/23873 [00:00&lt;00:00, 611589.28it/s]"
          }
        },
        "ffc7f6115ec243c7a5aabc0b3c8eee0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9edaecea7b047d2923d2807b816a22d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b43093c158d41c99b9c0adc6fdcb52f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "05732f51858749e9af0e5dd9201bd9f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcf9d309f6374f388dbb442db2a907a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e36106515ae64baca9313ea6a33e05fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed65a240671c48079465b9425dfcb876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamedElsayed002/DeepLearning_Study/blob/master/DeepLearningKeras3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
        "\n",
        "## UCI Pima Diabetes Dataset\n",
        "\n",
        "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
        "\n",
        "\n",
        "### Attributes: (all numeric-valued)\n",
        "   1. Number of times pregnant\n",
        "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "   3. Diastolic blood pressure (mm Hg)\n",
        "   4. Triceps skin fold thickness (mm)\n",
        "   5. 2-Hour serum insulin (mu U/ml)\n",
        "   6. Body mass index (weight in kg/(height in m)^2)\n",
        "   7. Diabetes pedigree function\n",
        "   8. Age (years)\n",
        "   9. Class variable (0 or 1)"
      ],
      "metadata": {
        "id": "N3UrWmPHXxka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup\n",
        "import warnings\n",
        "import skillsnetwork\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Import keras objects for Deep Learning\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input , Dense , Flatten , Dropout , BatchNormalization\n",
        "from keras.optimizers import Adam , SGD , RMSprop\n"
      ],
      "metadata": {
        "id": "feM_U0GcXxz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Load in the data set\n",
        "await skillsnetwork.prepare(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/labs/Module2/L2/diabetes.csv\", overwrite=True)\n",
        "\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv('./diabetes.csv', names=names, header=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35,
          "referenced_widgets": [
            "edbd2a077ce24db899b2e8c68964056f",
            "9b830ece7be4464caf0b204849638887",
            "8a9e4301c8864d66aececde9c1bb3340",
            "a6752d168a854a4aaa7a2484263b9c23",
            "ffc7f6115ec243c7a5aabc0b3c8eee0e",
            "e9edaecea7b047d2923d2807b816a22d",
            "1b43093c158d41c99b9c0adc6fdcb52f",
            "05732f51858749e9af0e5dd9201bd9f4",
            "fcf9d309f6374f388dbb442db2a907a5",
            "e36106515ae64baca9313ea6a33e05fe",
            "ed65a240671c48079465b9425dfcb876"
          ]
        },
        "id": "F-CjFA_xYSnD",
        "outputId": "35f540e7-7e2e-4807-caf8-0d4f7c6fed21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading diabetes.csv:   0%|          | 0/23873 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edbd2a077ce24db899b2e8c68964056f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to '.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "F_UOYNyUYuV2",
        "outputId": "e19d82e0-c3e4-43b3-9fe8-797c5c2366ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "97                1                      71              48              18   \n",
              "343               5                     122              86               0   \n",
              "750               4                     136              70               0   \n",
              "704               4                     110              76              20   \n",
              "14                5                     166              72              19   \n",
              "\n",
              "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "97        76  20.4              0.323   22             0  \n",
              "343        0  34.7              0.290   33             0  \n",
              "750        0  31.2              1.182   22             1  \n",
              "704      100  28.4              0.118   27             0  \n",
              "14       175  25.8              0.587   51             1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-681f5611-72bd-490a-aaa3-9d3cdc7efb38\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>1</td>\n",
              "      <td>71</td>\n",
              "      <td>48</td>\n",
              "      <td>18</td>\n",
              "      <td>76</td>\n",
              "      <td>20.4</td>\n",
              "      <td>0.323</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>5</td>\n",
              "      <td>122</td>\n",
              "      <td>86</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>34.7</td>\n",
              "      <td>0.290</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750</th>\n",
              "      <td>4</td>\n",
              "      <td>136</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31.2</td>\n",
              "      <td>1.182</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>704</th>\n",
              "      <td>4</td>\n",
              "      <td>110</td>\n",
              "      <td>76</td>\n",
              "      <td>20</td>\n",
              "      <td>100</td>\n",
              "      <td>28.4</td>\n",
              "      <td>0.118</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5</td>\n",
              "      <td>166</td>\n",
              "      <td>72</td>\n",
              "      <td>19</td>\n",
              "      <td>175</td>\n",
              "      <td>25.8</td>\n",
              "      <td>0.587</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-681f5611-72bd-490a-aaa3-9d3cdc7efb38')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-681f5611-72bd-490a-aaa3-9d3cdc7efb38 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-681f5611-72bd-490a-aaa3-9d3cdc7efb38');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a5e69b4d-a1d4-4545-8c9e-0d6ebf89d496\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a5e69b4d-a1d4-4545-8c9e-0d6ebf89d496')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a5e69b4d-a1d4-4545-8c9e-0d6ebf89d496 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"diabetes_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"times_pregnant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          5,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"glucose_tolerance_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 34,\n        \"min\": 71,\n        \"max\": 166,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          122,\n          166,\n          136\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"blood_pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 48,\n        \"max\": 86,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          86,\n          72,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skin_thickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 0,\n        \"max\": 20,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          19,\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 73,\n        \"min\": 0,\n        \"max\": 175,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          175,\n          76\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.427706698044766,\n        \"min\": 20.4,\n        \"max\": 34.7,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          34.7,\n          25.8,\n          31.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pedigree_function\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.41654711618255147,\n        \"min\": 0.118,\n        \"max\": 1.182,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.29,\n          0.587,\n          1.182\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 22,\n        \"max\": 51,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          33,\n          51,\n          22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_diabetes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = diabetes_df.iloc[:,:-1].values\n",
        "y = diabetes_df['has_diabetes'].values"
      ],
      "metadata": {
        "id": "XrDpFRGQY2Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ],
      "metadata": {
        "id": "ISabvREaY_rM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(y),np.mean(1-y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9k7EkY4ZCjq",
        "outputId": "45c260e9-06af-48a6-ed29-cec5f4bc6e87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Above we see that about 35% of the patients in this dataset have diabetes,\n",
        "# while 65% do not. This means we can get an accuracy of 65% without any model\n",
        "# just declare that no one has diabetes. we will calculate the ROC-AUC score to\n",
        "# evaluate performance of our model and also look at the accuracy as well to see if\n",
        "# we imporved upon the 65% accuracy"
      ],
      "metadata": {
        "id": "pzNFTmCdZGs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1: Get a baseline performance using Random Forest\n",
        "# To begin, and get a baseline for classifier performance:\n",
        "\n",
        "# Train a Random Forest model with 200 trees on the training data.\n",
        "# Calculate the accuracy and roc_auc_score of the predictions.\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=200)\n",
        "rf_model.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "w6EuDRVSZp7M",
        "outputId": "bd357258-86e1-467b-ca6b-cf0be58a599a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_rf = rf_model.predict(X_test)\n",
        "y_pred_prob_rf = rf_model.predict_log_proba(X_test)\n",
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
        "# print(roc_auc_score(y_test,y_pred_prob_rf))\n",
        "# print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbDImHOzaHaO",
        "outputId": "2d569cac-f9ed-4514-9cb9-d984d12b422e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
        "### END SOLUTION"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "odh_jx9JaXM-",
        "outputId": "ba08f786-d9ed-4553-fea5-573c0ad27f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input contains infinity or a value too large for dtype('float64').",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0ba9327fe982>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n\u001b[1;32m      8\u001b[0m            xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplot_roc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_prob_rf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m### END SOLUTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-0ba9327fe982>\u001b[0m in \u001b[0;36mplot_roc\u001b[0;34m(y_test, y_pred, model_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_roc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'k-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'k--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# roc curve for random model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.8\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     \"\"\"\n\u001b[0;32m--> 992\u001b[0;31m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[1;32m    993\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    753\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0;31m# Filter out zero-weighted samples, as they should not impact the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36massert_all_finite\u001b[0;34m(X, allow_nan, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mdocumentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \"\"\"\n\u001b[0;32m--> 190\u001b[0;31m     _assert_all_finite(\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains infinity or a value too large for dtype('float64')."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a single hidden layer neural network\n",
        "\n",
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ],
      "metadata": {
        "id": "VbA288r_brzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = Sequential()\n",
        "model_1.add(Dense(12,input_shape=(8,),activation='sigmoid'))\n",
        "model_1.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "qJoFVGRjb906"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4ZJM4eIcQ16",
        "outputId": "1188c73d-15df-4782-807e-c2277640ac6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12)                108       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121 (484.00 Byte)\n",
            "Trainable params: 121 (484.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprehension question:\n",
        "# Why do we have 121 parameters? Does that make sense?\n",
        "# Let's fit our model for 200 epochs\n",
        "\n",
        "model_1.compile(SGD(lr = .003),\"binary_crossentropy\",metrics=['accuracy'])\n",
        "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY0GSLSAcTT-",
        "outputId": "aa4f7346-536d-46f8-992f-b6421ef94aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 16ms/step - loss: 0.8230 - accuracy: 0.3351 - val_loss: 0.7844 - val_accuracy: 0.3698\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7679 - accuracy: 0.3490 - val_loss: 0.7401 - val_accuracy: 0.3646\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7288 - accuracy: 0.3802 - val_loss: 0.7088 - val_accuracy: 0.4167\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7009 - accuracy: 0.5156 - val_loss: 0.6865 - val_accuracy: 0.5365\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6811 - accuracy: 0.5729 - val_loss: 0.6705 - val_accuracy: 0.6302\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6667 - accuracy: 0.6267 - val_loss: 0.6588 - val_accuracy: 0.6719\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6560 - accuracy: 0.6562 - val_loss: 0.6501 - val_accuracy: 0.6927\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.6684 - val_loss: 0.6435 - val_accuracy: 0.7031\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6417 - accuracy: 0.6632 - val_loss: 0.6383 - val_accuracy: 0.6875\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6366 - accuracy: 0.6632 - val_loss: 0.6342 - val_accuracy: 0.6719\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.6597 - val_loss: 0.6307 - val_accuracy: 0.6562\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6291 - accuracy: 0.6597 - val_loss: 0.6277 - val_accuracy: 0.6562\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6262 - accuracy: 0.6597 - val_loss: 0.6251 - val_accuracy: 0.6562\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.6580 - val_loss: 0.6227 - val_accuracy: 0.6562\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6210 - accuracy: 0.6615 - val_loss: 0.6205 - val_accuracy: 0.6562\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6188 - accuracy: 0.6615 - val_loss: 0.6185 - val_accuracy: 0.6562\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6167 - accuracy: 0.6632 - val_loss: 0.6166 - val_accuracy: 0.6562\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.6632 - val_loss: 0.6147 - val_accuracy: 0.6562\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6128 - accuracy: 0.6632 - val_loss: 0.6129 - val_accuracy: 0.6562\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6109 - accuracy: 0.6649 - val_loss: 0.6112 - val_accuracy: 0.6562\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6092 - accuracy: 0.6632 - val_loss: 0.6094 - val_accuracy: 0.6562\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6073 - accuracy: 0.6649 - val_loss: 0.6077 - val_accuracy: 0.6667\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6057 - accuracy: 0.6649 - val_loss: 0.6061 - val_accuracy: 0.6667\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6040 - accuracy: 0.6667 - val_loss: 0.6044 - val_accuracy: 0.6667\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6023 - accuracy: 0.6649 - val_loss: 0.6028 - val_accuracy: 0.6771\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6006 - accuracy: 0.6667 - val_loss: 0.6012 - val_accuracy: 0.6771\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5989 - accuracy: 0.6667 - val_loss: 0.5997 - val_accuracy: 0.6771\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5973 - accuracy: 0.6667 - val_loss: 0.5981 - val_accuracy: 0.6771\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5957 - accuracy: 0.6667 - val_loss: 0.5966 - val_accuracy: 0.6771\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5941 - accuracy: 0.6701 - val_loss: 0.5950 - val_accuracy: 0.6771\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5925 - accuracy: 0.6684 - val_loss: 0.5935 - val_accuracy: 0.6771\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.6753 - val_loss: 0.5920 - val_accuracy: 0.6771\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5895 - accuracy: 0.6736 - val_loss: 0.5906 - val_accuracy: 0.6771\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5880 - accuracy: 0.6771 - val_loss: 0.5891 - val_accuracy: 0.6771\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5864 - accuracy: 0.6771 - val_loss: 0.5877 - val_accuracy: 0.6771\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5849 - accuracy: 0.6771 - val_loss: 0.5862 - val_accuracy: 0.6823\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.6788 - val_loss: 0.5848 - val_accuracy: 0.6771\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.6771 - val_loss: 0.5834 - val_accuracy: 0.6771\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.6806 - val_loss: 0.5821 - val_accuracy: 0.6823\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5792 - accuracy: 0.6823 - val_loss: 0.5807 - val_accuracy: 0.6875\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5778 - accuracy: 0.6858 - val_loss: 0.5793 - val_accuracy: 0.6875\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5763 - accuracy: 0.6892 - val_loss: 0.5780 - val_accuracy: 0.6927\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5750 - accuracy: 0.6892 - val_loss: 0.5767 - val_accuracy: 0.6927\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.6892 - val_loss: 0.5754 - val_accuracy: 0.6979\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5723 - accuracy: 0.6892 - val_loss: 0.5741 - val_accuracy: 0.6979\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5709 - accuracy: 0.6875 - val_loss: 0.5728 - val_accuracy: 0.7031\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5695 - accuracy: 0.6927 - val_loss: 0.5715 - val_accuracy: 0.6979\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.6910 - val_loss: 0.5703 - val_accuracy: 0.7083\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.6910 - val_loss: 0.5690 - val_accuracy: 0.7135\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.6875 - val_loss: 0.5678 - val_accuracy: 0.7135\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.6910 - val_loss: 0.5666 - val_accuracy: 0.7240\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.6892 - val_loss: 0.5654 - val_accuracy: 0.7240\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5617 - accuracy: 0.6927 - val_loss: 0.5642 - val_accuracy: 0.7240\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.6927 - val_loss: 0.5630 - val_accuracy: 0.7292\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.6944 - val_loss: 0.5618 - val_accuracy: 0.7292\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.6944 - val_loss: 0.5607 - val_accuracy: 0.7292\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5568 - accuracy: 0.6997 - val_loss: 0.5595 - val_accuracy: 0.7344\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5556 - accuracy: 0.6997 - val_loss: 0.5584 - val_accuracy: 0.7344\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5544 - accuracy: 0.6997 - val_loss: 0.5573 - val_accuracy: 0.7396\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.7031 - val_loss: 0.5562 - val_accuracy: 0.7396\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7101 - val_loss: 0.5551 - val_accuracy: 0.7500\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7101 - val_loss: 0.5541 - val_accuracy: 0.7500\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5498 - accuracy: 0.7118 - val_loss: 0.5530 - val_accuracy: 0.7552\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7135 - val_loss: 0.5519 - val_accuracy: 0.7552\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.7135 - val_loss: 0.5509 - val_accuracy: 0.7552\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.7135 - val_loss: 0.5499 - val_accuracy: 0.7552\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.7170 - val_loss: 0.5489 - val_accuracy: 0.7656\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7257 - val_loss: 0.5479 - val_accuracy: 0.7656\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7257 - val_loss: 0.5469 - val_accuracy: 0.7656\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.7309 - val_loss: 0.5459 - val_accuracy: 0.7656\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.7292 - val_loss: 0.5449 - val_accuracy: 0.7656\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7326 - val_loss: 0.5440 - val_accuracy: 0.7656\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7344 - val_loss: 0.5431 - val_accuracy: 0.7708\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.7378 - val_loss: 0.5421 - val_accuracy: 0.7760\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7378 - val_loss: 0.5412 - val_accuracy: 0.7812\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7396 - val_loss: 0.5403 - val_accuracy: 0.7812\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.7361 - val_loss: 0.5394 - val_accuracy: 0.7812\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7378 - val_loss: 0.5385 - val_accuracy: 0.7812\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.7326 - val_loss: 0.5377 - val_accuracy: 0.7812\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7344 - val_loss: 0.5368 - val_accuracy: 0.7812\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7378 - val_loss: 0.5360 - val_accuracy: 0.7812\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7396 - val_loss: 0.5351 - val_accuracy: 0.7760\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7378 - val_loss: 0.5343 - val_accuracy: 0.7760\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7431 - val_loss: 0.5335 - val_accuracy: 0.7760\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5273 - accuracy: 0.7431 - val_loss: 0.5327 - val_accuracy: 0.7760\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7448 - val_loss: 0.5319 - val_accuracy: 0.7760\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.7448 - val_loss: 0.5311 - val_accuracy: 0.7760\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7448 - val_loss: 0.5304 - val_accuracy: 0.7708\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.7413 - val_loss: 0.5296 - val_accuracy: 0.7708\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.7483 - val_loss: 0.5289 - val_accuracy: 0.7656\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7465 - val_loss: 0.5281 - val_accuracy: 0.7708\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7483 - val_loss: 0.5274 - val_accuracy: 0.7708\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7500 - val_loss: 0.5267 - val_accuracy: 0.7708\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5196 - accuracy: 0.7500 - val_loss: 0.5260 - val_accuracy: 0.7708\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5187 - accuracy: 0.7517 - val_loss: 0.5253 - val_accuracy: 0.7708\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5179 - accuracy: 0.7517 - val_loss: 0.5246 - val_accuracy: 0.7708\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5173 - accuracy: 0.7500 - val_loss: 0.5239 - val_accuracy: 0.7708\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5164 - accuracy: 0.7517 - val_loss: 0.5233 - val_accuracy: 0.7760\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5156 - accuracy: 0.7517 - val_loss: 0.5226 - val_accuracy: 0.7760\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5149 - accuracy: 0.7517 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5141 - accuracy: 0.7517 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5134 - accuracy: 0.7517 - val_loss: 0.5207 - val_accuracy: 0.7760\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5127 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.7760\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5119 - accuracy: 0.7535 - val_loss: 0.5195 - val_accuracy: 0.7760\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5112 - accuracy: 0.7535 - val_loss: 0.5189 - val_accuracy: 0.7708\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5105 - accuracy: 0.7587 - val_loss: 0.5183 - val_accuracy: 0.7708\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5099 - accuracy: 0.7587 - val_loss: 0.5177 - val_accuracy: 0.7708\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5091 - accuracy: 0.7604 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5084 - accuracy: 0.7639 - val_loss: 0.5166 - val_accuracy: 0.7708\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5078 - accuracy: 0.7639 - val_loss: 0.5160 - val_accuracy: 0.7708\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5071 - accuracy: 0.7639 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5065 - accuracy: 0.7639 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5058 - accuracy: 0.7656 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5051 - accuracy: 0.7656 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5046 - accuracy: 0.7656 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5039 - accuracy: 0.7656 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5033 - accuracy: 0.7656 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5028 - accuracy: 0.7656 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5021 - accuracy: 0.7656 - val_loss: 0.5114 - val_accuracy: 0.7708\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5016 - accuracy: 0.7656 - val_loss: 0.5109 - val_accuracy: 0.7760\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5010 - accuracy: 0.7639 - val_loss: 0.5105 - val_accuracy: 0.7760\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5004 - accuracy: 0.7622 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4998 - accuracy: 0.7656 - val_loss: 0.5096 - val_accuracy: 0.7708\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.7656 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.7639 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4982 - accuracy: 0.7674 - val_loss: 0.5083 - val_accuracy: 0.7708\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4976 - accuracy: 0.7656 - val_loss: 0.5079 - val_accuracy: 0.7708\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4971 - accuracy: 0.7674 - val_loss: 0.5075 - val_accuracy: 0.7656\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7691 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7656 - val_loss: 0.5066 - val_accuracy: 0.7656\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7674 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.7674 - val_loss: 0.5059 - val_accuracy: 0.7656\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7674 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7691 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7691 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7691 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4927 - accuracy: 0.7691 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.7674 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.7691 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7726 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7726 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.7708 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7708 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7708 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7691 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.7708 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7674 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.7708 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7691 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7708 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.7691 - val_loss: 0.4994 - val_accuracy: 0.7656\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7691 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7674 - val_loss: 0.4989 - val_accuracy: 0.7656\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7674 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7674 - val_loss: 0.4984 - val_accuracy: 0.7656\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7674 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7691 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7691 - val_loss: 0.4976 - val_accuracy: 0.7656\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.7691 - val_loss: 0.4974 - val_accuracy: 0.7656\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7691 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7691 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7691 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7708 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7708 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7691 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7691 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7708 - val_loss: 0.4956 - val_accuracy: 0.7656\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7708 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7708 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7691 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.7708 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7726 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.7726 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7726 - val_loss: 0.4940 - val_accuracy: 0.7604\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7726 - val_loss: 0.4938 - val_accuracy: 0.7604\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7726 - val_loss: 0.4936 - val_accuracy: 0.7604\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7726 - val_loss: 0.4935 - val_accuracy: 0.7604\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.7760 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7726 - val_loss: 0.4931 - val_accuracy: 0.7604\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7726 - val_loss: 0.4930 - val_accuracy: 0.7604\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7778 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4761 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7795 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7795 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7778 - val_loss: 0.4916 - val_accuracy: 0.7604\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7760 - val_loss: 0.4914 - val_accuracy: 0.7604\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7778 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7778 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7795 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7795 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7795 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7795 - val_loss: 0.4907 - val_accuracy: 0.7604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
        "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "Vq9alaHQdBaV",
        "outputId": "cfbcda6c-3e53-42d2-9dc3-7076147f620c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Sequential' object has no attribute 'predict_classes'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-52856171b604>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#  One is a hard decision, the other is a probabilitistic score.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_pred_class_nn_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_pred_prob_nn_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred_class_nn_1[:10]"
      ],
      "metadata": {
        "id": "zkhzxkOmdfC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print model performance and plot the roc curve\n",
        "# print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "# print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "# plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ],
      "metadata": {
        "id": "ad24qrFXvRFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_hist_1.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-_JiTPIv2j2",
        "outputId": "15b3cafa-1b45-47f8-cf7f-1ae670f73131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "fFYcCLvDv7YN",
        "outputId": "bfcd253e-a802-4e41-f47a-f85ee8347a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ccfa8c1cd30>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Looks like the losses are still going down on both the training set and validation set. this suggests that the model might benefit from fruther\n",
        "# training. let's train the model a little more and see what happens. note that it will pick up from where it left off. train for 1000 more epochs\n",
        "\n",
        "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCoOaP_iwAlW",
        "outputId": "a4a082e2-ecb3-418c-dca4-265e565fb90a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.7795 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7778 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4725 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.7778 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4720 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7760\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4708 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4705 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7760\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7795 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.7795 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7708\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7708\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7708\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7812 - val_loss: 0.4886 - val_accuracy: 0.7708\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7812 - val_loss: 0.4885 - val_accuracy: 0.7708\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4692 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7708\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4691 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7708\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4689 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7708\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7708\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7795 - val_loss: 0.4882 - val_accuracy: 0.7708\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7830 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7830 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7830 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7708\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7708\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7708\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7708\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.7847 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.7847 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.7847 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4663 - accuracy: 0.7865 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7882 - val_loss: 0.4867 - val_accuracy: 0.7708\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7708\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7708\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7865 - val_loss: 0.4866 - val_accuracy: 0.7708\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7865 - val_loss: 0.4866 - val_accuracy: 0.7708\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7865 - val_loss: 0.4866 - val_accuracy: 0.7708\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7708\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7882 - val_loss: 0.4865 - val_accuracy: 0.7708\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7865 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7865 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7865 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7865 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7865 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7865 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7847 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7847 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.7865 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7847 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7847 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7847 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7847 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7847 - val_loss: 0.4860 - val_accuracy: 0.7656\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7847 - val_loss: 0.4860 - val_accuracy: 0.7656\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7847 - val_loss: 0.4860 - val_accuracy: 0.7656\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7656\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7656\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7656\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7812 - val_loss: 0.4859 - val_accuracy: 0.7656\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7830 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7830 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7812 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7830 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7830 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7830 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7830 - val_loss: 0.4858 - val_accuracy: 0.7604\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4626 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7604\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7847 - val_loss: 0.4855 - val_accuracy: 0.7604\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7847 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7847 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7847 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7847 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7847 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7865 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7847 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7847 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7847 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7865 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7847 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7865 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7847 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7865 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7847 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7604\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7847 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7795 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7795 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4582 - accuracy: 0.7795 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4581 - accuracy: 0.7812 - val_loss: 0.4856 - val_accuracy: 0.7708\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4581 - accuracy: 0.7812 - val_loss: 0.4856 - val_accuracy: 0.7708\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7708\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7708\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7708\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7708\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7812 - val_loss: 0.4856 - val_accuracy: 0.7708\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7812 - val_loss: 0.4856 - val_accuracy: 0.7708\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7708\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7708\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7708\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7812 - val_loss: 0.4856 - val_accuracy: 0.7708\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7812 - val_loss: 0.4856 - val_accuracy: 0.7708\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7812 - val_loss: 0.4856 - val_accuracy: 0.7708\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7830 - val_loss: 0.4856 - val_accuracy: 0.7708\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7812 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7812 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7812 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7812 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7812 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4576 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7812 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4576 - accuracy: 0.7812 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7812 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4576 - accuracy: 0.7847 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7812 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7847 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7847 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7812 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7830 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7812 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7812 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7830 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7812 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7847 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7830 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7812 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7847 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7847 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7847 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7830 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7847 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7830 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7812 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7830 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7847 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7830 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7847 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7830 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7812 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7812 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7847 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7812 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.7847 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4569 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4569 - accuracy: 0.7812 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.7812 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4569 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4570 - accuracy: 0.7812 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.7812 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4569 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4568 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.7812 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4568 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.7812 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.7847 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4568 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4568 - accuracy: 0.7812 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4567 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4567 - accuracy: 0.7847 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4566 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4567 - accuracy: 0.7812 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4566 - accuracy: 0.7847 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4567 - accuracy: 0.7812 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4567 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4566 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4566 - accuracy: 0.7812 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4566 - accuracy: 0.7812 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4565 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7812 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7812 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7812 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7812 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7812 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7812 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7812 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4563 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7812 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.7812 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7812 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.7812 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7812 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7812 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4558 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.4558 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4558 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4558 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4558 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4557 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7795 - val_loss: 0.4861 - val_accuracy: 0.7708\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4555 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4555 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4555 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4554 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7778 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4554 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4553 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4553 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7830 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.7778 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4551 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4550 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.7795 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4550 - accuracy: 0.7795 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4550 - accuracy: 0.7795 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4549 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.7795 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.7795 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.7795 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.7778 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4549 - accuracy: 0.7830 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4549 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4548 - accuracy: 0.7795 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4548 - accuracy: 0.7795 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4548 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4548 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4548 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4548 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4547 - accuracy: 0.7795 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4548 - accuracy: 0.7830 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4548 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4547 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4547 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4547 - accuracy: 0.7830 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4546 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4546 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7795 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4545 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4545 - accuracy: 0.7795 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7795 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7795 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4545 - accuracy: 0.7795 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4544 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4544 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4544 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4544 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.7795 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4544 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4544 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4541 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4541 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4538 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4530 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4530 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4530 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4530 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4529 - accuracy: 0.7847 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4528 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4528 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4527 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4527 - accuracy: 0.7847 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4527 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4527 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4527 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4526 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4525 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4524 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.7812 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7812 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4520 - accuracy: 0.7830 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4520 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7604\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7552\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4520 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7552\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7812 - val_loss: 0.4867 - val_accuracy: 0.7552\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7552\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.7812 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4515 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4514 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4514 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4514 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4514 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7552\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7812 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7812 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7812 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.7812 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7812 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7552\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4508 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7812 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4507 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4507 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4507 - accuracy: 0.7812 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4506 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4507 - accuracy: 0.7812 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4506 - accuracy: 0.7812 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4506 - accuracy: 0.7812 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4506 - accuracy: 0.7812 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4505 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4505 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4505 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4505 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4505 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4504 - accuracy: 0.7812 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4504 - accuracy: 0.7865 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4505 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.7812 - val_loss: 0.4870 - val_accuracy: 0.7552\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4504 - accuracy: 0.7812 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4504 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4503 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4503 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4503 - accuracy: 0.7847 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4503 - accuracy: 0.7812 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4504 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4502 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4502 - accuracy: 0.7812 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.7847 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7847 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7847 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7552\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7812 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.7847 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7847 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7812 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7812 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7812 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7552\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.7812 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7865 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7812 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7552\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7830 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7830 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.7830 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4484 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4484 - accuracy: 0.7812 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4484 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4483 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4483 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4483 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7812 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4482 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4482 - accuracy: 0.7812 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4482 - accuracy: 0.7812 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4481 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4481 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4480 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4480 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4481 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4480 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4479 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4480 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4479 - accuracy: 0.7812 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4478 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4478 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4478 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4478 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4478 - accuracy: 0.7812 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4477 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7865 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7865 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7865 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7812 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7865 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.7865 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7865 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.7865 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.7865 - val_loss: 0.4879 - val_accuracy: 0.7604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(run_hist_1.history[\"loss\"])\n",
        "m = len(run_hist_1b.history['loss'])\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
        "\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "VtvJ9LSxwu1N",
        "outputId": "2fe01ae4-62ef-436f-eefe-070c75d16c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ccfa8b38e50>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABRQAAAKTCAYAAABo9IQGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACAkUlEQVR4nOzdeXhU9fn+8XsyIQlZ2UlgIgETEDCABaRAq6jRoJaCKyKKQFikoCCySFkEQXABxB2kLPq1Kmq19ScUxAhqBQGhKFZEokCIsiMJBCEwM78/hgyZrDPZzpzM+3Vd5wpz5izPJNHK3edzHovT6XQKAAAAAAAAALwQZHQBAAAAAAAAAMyDQBEAAAAAAACA1wgUAQAAAAAAAHiNQBEAAAAAAACA1wgUAQAAAAAAAHiNQBEAAAAAAACA1wgUAQAAAAAAAHgt2OgCKoPD4dAvv/yiqKgoWSwWo8sBAAAAAAAATMXpdOrkyZNq0qSJgoJK70GsEYHiL7/8ovj4eKPLAAAAAAAAAExt//79stlspR5TIwLFqKgoSa4PHB0dbXA1AAAAAAAAgLnk5OQoPj7enbOVpkYEivnLnKOjowkUAQAAAAAAgHLy5nGCDGUBAAAAAAAA4DUCRQAAAAAAAABeI1AEAAAAAAAA4LUa8QxFAAAAAAAQmBwOh/Ly8owuAzCFWrVqyWq1Vvg6BIoAAAAAAMCU8vLytGfPHjkcDqNLAUyjTp06io2N9Wr4SkkIFAEAAAAAgOk4nU4dOHBAVqtV8fHxCgriqW5AaZxOp06fPq3Dhw9LkuLi4sp9LQJFAAAAAABgOufPn9fp06fVpEkThYeHG10OYAq1a9eWJB0+fFiNGjUq9/Jn4nsAAAAAAGA6drtdkhQSEmJwJYC55Afw586dK/c1CBQBAAAAAIBpVeQ5cEAgqox/ZggUAQAAAAAAAHiNQBEAAAAAAACA1wgUAQAAAAAATCwhIUELFiwwugwEEAJFAAAAAACAamCxWErdpk+fXq7rbtmyRcOGDatQbT169NCYMWMqdI3qlJCQ4P6+hYeHKzk5WX/729+q5d6PP/64unXrpvDwcNWpU6da7ulvCBQBAAAAAEBgy8qS1q1zfa1CBw4ccG8LFixQdHS0x75x48a5j3U6nTp//rxX123YsKF7cm8geeyxx3TgwAF9++23uueeezR06FD9+9//rvL75uXl6Y477tCIESOq/F7+ikARAAAAAACYn9Mp5eb6vr30ktSsmXTtta6vL73k+zWcTq9KjI2NdW8xMTGyWCzu199//72ioqL073//Wx07dlRoaKj+85//6Mcff1Tv3r3VuHFjRUZGqnPnzvr44489rlt4ybPFYtHf/vY33XLLLQoPD1dSUpI++OCDCn17//GPf6ht27YKDQ1VQkKC5s2b5/H+Sy+9pKSkJIWFhalx48a6/fbb3e+9++67Sk5OVu3atVW/fn2lpKQoNze3QvVIUlRUlGJjY9WiRQtNnDhR9erV09q1ayVJe/fulcVi0fbt293HnzhxQhaLRevXr5ckrV+/XhaLRenp6erUqZPCw8PVrVs37dq1q9T7zpgxQw899JCSk5Mr/BnMikARAAAAAACY3+nTUmSk79vIkZLD4bqGw+F67es1Tp+utI/xyCOP6IknntDOnTvVrl07nTp1SjfddJPS09P13//+Vz179lSvXr2UmZlZ6nVmzJihO++8U998841uuukm9e/fX8ePHy9XTVu3btWdd96pu+66Szt27ND06dM1depULV++XJL01Vdf6cEHH9Rjjz2mXbt2afXq1brqqqskuboy+/Xrp8GDB2vnzp1av369br31Vjm9DGG94XA49I9//EO//vqrQkJCfD5/8uTJmjdvnr766isFBwdr8ODBlVZbTRVsdAEAAAAAAABweeyxx3T99de7X9erV0/t27d3v545c6bef/99ffDBBxo1alSJ1xk4cKD69esnSZo9e7aee+45bd68WT179vS5pvnz5+u6667T1KlTJUktW7bUd999p6effloDBw5UZmamIiIi9Kc//UlRUVFq1qyZrrjiCkmuQPH8+fO69dZb1axZM0mqtM6+iRMnasqUKTp79qzOnz+vevXqaciQIT5f5/HHH9fVV18tyRXo3nzzzTpz5ozCwsIqpc6aiA5FAAAAAABgfuHh0qlTvm27dklBhaIRq9W135frVOLzCzt16uTx+tSpUxo3bpxat26tOnXqKDIyUjt37iyzQ7Fdu3buP0dERCg6OlqHDx8uV007d+5U9+7dPfZ1795du3fvlt1u1/XXX69mzZqpRYsWuvfee/X3v/9dpy90bbZv317XXXedkpOTdccdd2jx4sX69ddfS7xX27ZtFRkZqcjISN14442l1jV+/Hht375dn3zyibp06aJnnnlGiYmJPn++gt+ruLg4SSr39ypQ0KEIAAAAAADMz2KRIiJ8O6dlS+mVV6ThwyW73RUmLlrk2m+QiEKfYdy4cVq7dq3mzp2rxMRE1a5dW7fffrvy8vJKvU6tWrU8XlssFjnyl3ZXsqioKG3btk3r16/XRx99pGnTpmn69OnasmWL6tSpo7Vr12rDhg366KOP9Pzzz2vy5MnatGmTmjdvXuRaq1at0rlz5yRJtWvXLvW+DRo0UGJiohITE/XOO+8oOTlZnTp1Ups2bRR0ISguuLQ6/7qFFfxeWSwWSaqy71VNQYciAAAAAAAIXGlp0t69rinPe/e6XvuRL774QgMHDtQtt9yi5ORkxcbGau/evdVaQ+vWrfXFF18Uqatly5ayWq2SpODgYKWkpOipp57SN998o7179+qTTz6R5ArpunfvrhkzZui///2vQkJC9P777xd7r2bNmrlDwqZNm3pdY3x8vPr27atJkyZJck2+llxLrvMVHNCCiqFDEQAAAAAABDabzbX5oaSkJL333nvq1auXLBaLpk6dWmXdc0eOHCkSusXFxenhhx9W586dNXPmTPXt21cbN27UCy+8oJdeekmS9OGHH+qnn37SVVddpbp162rVqlVyOBxq1aqVNm3apPT0dN1www1q1KiRNm3apCNHjqh169aVXv/o0aN1+eWX66uvvlKnTp30+9//Xk888YSaN2+uw4cPa8qUKZVyn8zMTB0/flyZmZmy2+3u71liYqIiIyMr5R7+jg5FAAAAAAAAPzV//nzVrVtX3bp1U69evZSamqrf/e53VXKvN954Q1dccYXHtnjxYv3ud7/T22+/rbfeekuXX365pk2bpscee0wDBw6UJNWpU0fvvfeerr32WrVu3VoLFy7Um2++qbZt2yo6OlqfffaZbrrpJrVs2VJTpkzRvHnzynw+Ynm0adNGN9xwg6ZNmyZJWrp0qc6fP6+OHTtqzJgxmjVrVqXcZ9q0abriiiv06KOP6tSpU+7v1VdffVUp1zcDi7My53QbJCcnRzExMcrOzlZ0dLTR5VSNrCxp924pKclv/18TAAAAAACqy5kzZ7Rnzx41b96cabyAD0r6Z8eXfI0ORTNYskRq1ky69lrX1yVLjK4IAAAAAAAAAYpA0d9lZUnDhkn5z0dwOFzTp7KyjK0LAAAAAAAAAYlA0d/t3n0xTMxnt0sZGcbUAwAAAAAAgIBGoOjvkpKkoEI/JqtVSkw0ph4AAAAAAAAENAJFf2ezSVOnXnxttUqLFjGYBQAAAAAAAIYgUDSD2293fY2JkfbuldLSDC0HAAAAAAAAgYtA0QzylzxbrXQmAgAAAAAAwFAEimZgtbq+2u3G1gEAAAAAAICAR6BoBgSKAAAAAACgBAkJCVqwYIHRZSCAECiaAYEiAAAAAACmZ7FYSt2mT59erutu2bJFw4YNq1BtPXr00JgxYyp0jeqUkJDg/r6Fh4crOTlZf/vb36r8vnv37lVaWpqaN2+u2rVr69JLL9Wjjz6qvLy8Kr+3Pwk2ugB4gUARAAAAAADTO3DggPvPK1as0LRp07Rr1y73vsjISPefnU6n7Ha7goPLjm4aNmxYuYWaxGOPPaahQ4fq9OnTeueddzR06FA1bdpUN954Y5Xd8/vvv5fD4dCiRYuUmJiob7/9VkOHDlVubq7mzp1bZff1N3QomgGBIgAAAAAAVefX36RdR11fq1BsbKx7i4mJkcVicb/+/vvvFRUVpX//+9/q2LGjQkND9Z///Ec//vijevfurcaNGysyMlKdO3fWxx9/7HHdwkueLRaL/va3v+mWW25ReHi4kpKS9MEHH1So9n/84x9q27atQkNDlZCQoHnz5nm8/9JLLykpKUlhYWFq3Lixbr/9dvd77777rpKTk1W7dm3Vr19fKSkpys3NrVA9khQVFaXY2Fi1aNFCEydOVL169bR27VpJrk5Ci8Wi7du3u48/ceKELBaL1q9fL0lav369LBaL0tPT1alTJ4WHh6tbt24eIW9hPXv21LJly3TDDTeoRYsW+vOf/6xx48bpvffeq/DnMRMCRTMgUAQAAAAAoHROp3T2vO/bp3ulKZ9Iz25yff10r+/XcDor7WM88sgjeuKJJ7Rz5061a9dOp06d0k033aT09HT997//Vc+ePdWrVy9lZmaWep0ZM2bozjvv1DfffKObbrpJ/fv31/Hjx8tV09atW3XnnXfqrrvu0o4dOzR9+nRNnTpVy5cvlyR99dVXevDBB/XYY49p165dWr16ta666ipJrq7Mfv36afDgwdq5c6fWr1+vW2+9Vc5K/J45HA794x//0K+//qqQkBCfz588ebLmzZunr776SsHBwRo8eLBP52dnZ6tevXo+39fMWPJsBvmBoiQ5HFIQOTAAAAAAAB7y7NJDayp2DaekFf9zbb54JlUKrZyI5bHHHtP111/vfl2vXj21b9/e/XrmzJl6//339cEHH2jUqFElXmfgwIHq16+fJGn27Nl67rnntHnzZvXs2dPnmubPn6/rrrtOU6dOlSS1bNlS3333nZ5++mkNHDhQmZmZioiI0J/+9CdFRUWpWbNmuuKKKyS5AsXz58/r1ltvVbNmzSRJycnJPtdQnIkTJ2rKlCk6e/aszp8/r3r16mnIkCE+X+fxxx/X1VdfLckV6N588806c+aMwsLCyjw3IyNDzz//fEAtd5boUDSHgoEiXYoAAAAAANRYnTp18nh96tQpjRs3Tq1bt1adOnUUGRmpnTt3ltmh2K5dO/efIyIiFB0drcOHD5erpp07d6p79+4e+7p3767du3fLbrfr+uuvV7NmzdSiRQvde++9+vvf/67Tp09Lktq3b6/rrrtOycnJuuOOO7R48WL9+uuvJd6rbdu2ioyMVGRkZJnPQhw/fry2b9+uTz75RF26dNEzzzyjxMREnz9fwe9VXFycJHn1vfr555/Vs2dP3XHHHRo6dKjP9zUzOhTNoHCgWKuWcbUAAAAAAOCPQqyuTkFfnDgjPfapqzMxn0XStKulOmV3p3ncu5JERER4vB43bpzWrl2ruXPnKjExUbVr19btt99e5lThWoWyA4vFIofDUWl1FhQVFaVt27Zp/fr1+uijjzRt2jRNnz5dW7ZsUZ06dbR27Vpt2LBBH330kZ5//nlNnjxZmzZtUvPmzYtca9WqVTp37pwkqXbt2qXet0GDBkpMTFRiYqLeeecdJScnq1OnTmrTpo2CLqzuLLi0Ov+6hRX8XlksFkkq83v1yy+/6JprrlG3bt30yiuvlHpsTUSHohnQoQgAAAAAQOksFteyY1+2xpHS3clSkCtEUpDF9bpxpG/XuRBCVYUvvvhCAwcO1C233KLk5GTFxsZq7969VXa/4rRu3VpffPFFkbpatmwp64XMIjg4WCkpKXrqqaf0zTffaO/evfrkk08kuUK67t27a8aMGfrvf/+rkJAQvf/++8Xeq1mzZu6QsGnTpl7XGB8fr759+2rSpEmSLk6+LjhZu+CAlor4+eef1aNHD3Xs2FHLli1zh5eBhA5FMyBQBAAAAACganS/RGrTUDpyWmoYLtUtvSuuuiUlJem9995Tr169ZLFYNHXq1CrrNDxy5EiR0C0uLk4PP/ywOnfurJkzZ6pv377auHGjXnjhBb300kuSpA8//FA//fSTrrrqKtWtW1erVq2Sw+FQq1attGnTJqWnp+uGG25Qo0aNtGnTJh05ckStW7eu9PpHjx6tyy+/XF999ZU6deqk3//+93riiSfUvHlzHT58WFOmTKnwPfLDxGbNmmnu3Lk6cuSI+73Y2NgKX98sCBTNoPBQFgAAAAAAUHnq1va7IDHf/PnzNXjwYHXr1k0NGjTQxIkTlZOTUyX3euONN/TGG2947Js5c6amTJmit99+W9OmTdPMmTMVFxenxx57TAMHDpQk1alTR++9956mT5+uM2fOKCkpSW+++abatm2rnTt36rPPPtOCBQuUk5OjZs2aad68eWU+H7E82rRpoxtuuEHTpk3TqlWrtHTpUqWlpaljx45q1aqVnnrqKd1www0VusfatWuVkZGhjIwM2Ww2j/cqc3K1v7M4a8CnzcnJUUxMjLKzsxUdHW10OZXPbpeCL2S/R49K9esbWw8AAAAAAAY7c+aM9uzZo+bNm3s1jReAS0n/7PiSrwXeIm8zKrgWnyXPAAAAAAAAMBCBohlYLBcf8EqgCAAAAAAAAAMRKJpF/nMUCRQBAAAAAABgIAJFsyBQBAAAAAAAgB8gUDQLAkUAAAAAAAD4AQJFsyBQBAAAAAAAgB8gUDQLAkUAAAAAAAD4AQJFsyBQBAAAAAAAgB8gUDQLAkUAAAAAAAD4AQJFsyBQBAAAAAAAknr06KExY8a4XyckJGjBggWlnmOxWPTPf/6zwveurOvA3AgUzYJAEQAAAAAAU+vVq5d69uxZ7Huff/65LBaLvvnmG5+vu2XLFg0bNqyi5XmYPn26OnToUGT/gQMHdOONN1bqvQpbvny56tSpU6X3qEzTp0+XxWKRxWKR1WpVfHy8hg0bpuPHj1f5vT/77DP16tVLTZo0qdawl0DRLAgUAQAAAAAwtbS0NK1du1ZZWVlF3lu2bJk6deqkdu3a+Xzdhg0bKjw8vDJKLFNsbKxCQ0Or5V5m0rZtWx04cECZmZlatmyZVq9erREjRlT5fXNzc9W+fXu9+OKLVX6vgggUzSI/UHQ4jK0DAAAAAIAaJitLWrfO9bUq/elPf1LDhg21fPlyj/2nTp3SO++8o7S0NB07dkz9+vVT06ZNFR4eruTkZL355pulXrfwkufdu3frqquuUlhYmNq0aaO1a9cWOWfixIlq2bKlwsPD1aJFC02dOlXnzp2T5OoQnDFjhr7++mt3511+zYW74Hbs2KFrr71WtWvXVv369TVs2DCdOnXK/f7AgQPVp08fzZ07V3Fxcapfv75Gjhzpvld5ZGZmqnfv3oqMjFR0dLTuvPNOHTp0yP3+119/rWuuuUZRUVGKjo5Wx44d9dVXX0mS9u3bp169eqlu3bqKiIhQ27ZttWrVqnLXki84OFixsbFq2rSpUlJSdMcdd3h83wsvU5ekPn36aODAge7XCQkJmj17tgYPHqyoqChdcskleuWVV0q974033qhZs2bplltuqfBn8EW5AsUXX3xRCQkJCgsLU5cuXbR58+ZSj1+wYIFatWql2rVrKz4+Xg899JDOnDlToWsGHDoUAQAAAAAokdMp5eb6vr30ktSsmXTtta6vL73k+zWcTu9qDA4O1oABA7R8+XI5C5z0zjvvyG63q1+/fjpz5ow6duyolStX6ttvv9WwYcN07733ep2TOBwO3XrrrQoJCdGmTZu0cOFCTZw4schxUVFRWr58ub777js9++yzWrx4sZ555hlJUt++ffXwww+7u+4OHDigvn37FrlGbm6uUlNTVbduXW3ZskXvvPOOPv74Y40aNcrjuHXr1unHH3/UunXr9Oqrr2r58uVFQlVvORwO9e7dW8ePH9enn36qtWvX6qeffvKor3///rLZbNqyZYu2bt2qRx55RLVq1ZIkjRw5UmfPntVnn32mHTt26Mknn1RkZGS5ainJ3r17tWbNGoWEhPh87rx589SpUyf997//1V/+8heNGDFCu3btqtT6KkOwryesWLFCY8eO1cKFC9WlSxctWLBAqamp2rVrlxo1alTk+DfeeEOPPPKIli5dqm7duumHH37QwIEDZbFYNH/+/HJdMyARKAIAAAAAUKLTp6WK5kIOhzRypGvzxalTUkSEd8cOHjxYTz/9tD799FP16NFDkmu582233aaYmBjFxMRo3Lhx7uMfeOABrVmzRm+//bauvPLKMq//8ccf6/vvv9eaNWvUpEkTSdLs2bOLPPdwypQp7j8nJCRo3LhxeuuttzRhwgTVrl1bkZGR7q67krzxxhs6c+aMXnvtNUVc+Aa88MIL6tWrl5588kk1btxYklS3bl298MILslqtuuyyy3TzzTcrPT1dQ4cO9e6bVkB6erp27NihPXv2KD4+XpL02muvqW3bttqyZYs6d+6szMxMjR8/XpdddpkkKSkpyX1+ZmambrvtNiUnJ0uSWrRo4XMNxdmxY4ciIyNlt9vdTXT5uZcvbrrpJv3lL3+R5OoifeaZZ7Ru3Tq1atWqUuqsLD53KM6fP19Dhw7VoEGD1KZNGy1cuFDh4eFaunRpscdv2LBB3bt31913362EhATdcMMN6tevn0ey7us1AxKBIgAAAAAApnfZZZepW7du7swjIyNDn3/+udLS0iRJdrtdM2fOVHJysurVq6fIyEitWbNGmZmZXl1/586dio+Pd4eJktS1a9cix61YsULdu3dXbGysIiMjNWXKFK/vUfBe7du3d4eJktS9e3c5HA6Prrq2bdvKmp9rSIqLi9Phw4d9ulfBe8bHx7vDRElq06aN6tSpo507d0qSxo4dqyFDhiglJUVPPPGEfvzxR/exDz74oGbNmqXu3bvr0UcfLXUIzuzZsxUZGeneSvv+tGrVStu3b9eWLVs0ceJEpaam6oEHHvD58xV8hqbFYlFsbGy5v1dVyadAMS8vT1u3blVKSsrFCwQFKSUlRRs3biz2nG7dumnr1q3uAPGnn37SqlWrdNNNN5X7mmfPnlVOTo7HVuMRKAIAAAAAUKLwcFenoC/brl1SUKFkxGp17fflOr7OQ0lLS9M//vEPnTx5UsuWLdOll16qq6++WpL09NNP69lnn9XEiRO1bt06bd++XampqcrLy6uk75S0ceNG9e/fXzfddJM+/PBD/fe//9XkyZMr9R4F5S83zmexWOSowhkR06dP1//+9z/dfPPN+uSTT9SmTRu9//77kqQhQ4bop59+0r333qsdO3aoU6dOev7554u9zv3336/t27e7t4IhbWEhISFKTEzU5ZdfrieeeEJWq1UzZsxwvx8UFOSxzF1Ssc+RrO7vVXn5FCgePXpUdrvd3bKar3Hjxjp48GCx59x999167LHH9Ic//EG1atXSpZdeqh49euivf/1rua85Z84cdxtwTEyMRypdY+X/G45AEQAAAACAIiwW17JjX7aWLaVXXrnYw2O1SosWufb7ch2Lxbda77zzTgUFBemNN97Qa6+9psGDB8ty4SJffPGFevfurXvuuUft27dXixYt9MMPP3h97datW2v//v06cOCAe9+XX37pccyGDRvUrFkzTZ48WZ06dVJSUpL27dvncUxISIjsZWQQrVu31tdff63c3Fz3vi+++EJBQUFVtkQ3//Pt37/fve+7777TiRMn1KZNG/e+li1b6qGHHtJHH32kW2+9VcuWLXO/Fx8fr/vvv1/vvfeeHn74YS1evLjYe9WrV0+JiYnuLTjY+ycHTpkyRXPnztUvv/wiyTWJu+DPxG6369tvv/X6ev6myqc8r1+/XrNnz9ZLL72kbdu26b333tPKlSs1c+bMcl9z0qRJys7Odm8Ff4lqLDoUAQAAAACodGlp0t69rinPe/e6Xle1yMhI9e3bV5MmTdKBAwc8Jv0mJSVp7dq12rBhg3bu3Knhw4d7TDAuS0pKilq2bKn77rtPX3/9tT7//HNNnjzZ45ikpCRlZmbqrbfe0o8//qjnnnvO3cGXLyEhQXv27NH27dt19OhRnT17tsi9+vfvr7CwMN1333369ttvtW7dOj3wwAO69957izSO+cput3t0B27fvl07d+5USkqKkpOT1b9/f23btk2bN2/WgAEDdPXVV6tTp0767bffNGrUKK1fv1779u3TF198oS1btqh169aSpDFjxmjNmjXas2ePtm3bpnXr1rnfq0xdu3ZVu3btNHv2bEnStddeq5UrV2rlypX6/vvvNWLECJ04caLC9zl16pT7+yPJ/TPzdfm6r3wKFBs0aCCr1VrkF/nQoUMlPqRz6tSpuvfeezVkyBAlJyfrlltu0ezZszVnzhw5HI5yXTM0NFTR0dEeW41HoAgAAAAAQJWw2aQePVxfq0taWpp+/fVXpaameiylnTJlin73u98pNTVVPXr0UGxsrPr06eP1dYOCgvT+++/rt99+05VXXqkhQ4bo8ccf9zjmz3/+sx566CGNGjVKHTp00IYNGzR16lSPY2677Tb17NlT11xzjRo2bKg333yzyL3Cw8O1Zs0aHT9+XJ07d9btt9+u6667Ti+88IJv34xinDp1SldccYXH1qtXL1ksFv3rX/9S3bp1ddVVVyklJUUtWrTQihUrJElWq1XHjh3TgAED1LJlS91555268cYb3cuP7Xa7Ro4cqdatW6tnz55q2bKlXnrppQrXW5yHHnpIf/vb37R//34NHjxY9913nzv8bNGiha655poK3+Orr75yf38k1/Mjr7jiCk2bNq3C1y6NxVl4AXcZunTpoiuvvNK9vtzhcOiSSy7RqFGj9MgjjxQ5vmPHjkpJSdGTTz7p3vfmm28qLS1NJ0+elNVq9fmaheXk5CgmJkbZ2dk1N1zs1k3auFF67z3plluMrgYAAAAAAEOdOXNGe/bsUfPmzRUWFmZ0OYBplPTPji/5mveLvy8YO3as7rvvPnXq1ElXXnmlFixYoNzcXA0aNEiSNGDAADVt2lRz5syRJPXq1Uvz58/XFVdcoS5duigjI0NTp05Vr1693BN+yromRIciAAAAAAAA/ILPgWLfvn115MgRTZs2TQcPHlSHDh20evVq99r4zMxMBRUYkTRlyhRZLBZNmTJFP//8sxo2bKhevXp5tNuWdU2IQBEAAAAAAAB+weclz/4oIJY8X3ed9Mkn0t//Lt19t9HVAAAAAABgKJY8A+VTGUueq3zKMyoJHYoAAAAAAADwAwSKZpEfKDocxtYBAAAAAACAgEagaBZ0KAIAAAAAAMAPECiaBYEiAAAAAAAA/ACBolkQKAIAAAAAAMAPECiaBYEiAAAAAAAA/ACBolkQKAIAAAAAAEk9evTQmDFj3K8TEhK0YMGCUs+xWCz65z//WeF7V9Z1YG4EimZBoAgAAAAAgKn16tVLPXv2LPa9zz//XBaLRd98843P192yZYuGDRtW0fI8TJ8+XR06dCiy/8CBA7rxxhsr9V6FLV++XHXq1KnSe1Sm6dOny2KxyGKxyGq1Kj4+XsOGDdPx48er/N5z5sxR586dFRUVpUaNGqlPnz7atWtXld+XQNEsCBQBAAAAADC1tLQ0rV27VllZWUXeW7ZsmTp16qR27dr5fN2GDRsqPDy8MkosU2xsrEJDQ6vlXmbStm1bHThwQJmZmVq2bJlWr16tESNGVPl9P/30U40cOVJffvml1q5dq3PnzumGG25Qbm5uld6XQNEsgi78qAgUAQAAAACoVDl5Tu076VBOnrNK7/OnP/1JDRs21PLlyz32nzp1Su+8847S0tJ07Ngx9evXT02bNlV4eLiSk5P15ptvlnrdwkued+/erauuukphYWFq06aN1q5dW+SciRMnqmXLlgoPD1eLFi00depUnTt3TpKrQ3DGjBn6+uuv3Z13+TUXXvK8Y8cOXXvttapdu7bq16+vYcOG6dSpU+73Bw4cqD59+mju3LmKi4tT/fr1NXLkSPe9yiMzM1O9e/dWZGSkoqOjdeedd+rQoUPu97/++mtdc801ioqKUnR0tDp27KivvvpKkrRv3z716tVLdevWVUREhNq2batVq1aVu5Z8wcHBio2NVdOmTZWSkqI77rjD4/teeJm6JPXp00cDBw50v05ISNDs2bM1ePBgRUVF6ZJLLtErr7xS6n1Xr16tgQMHqm3btmrfvr2WL1+uzMxMbd26tcKfqTTBVXp1VB46FAEAAAAAKJHT6dQ5h+/n7Tju0MdZDjklWSSl2IKUXM+3/qtaQa6grSzBwcEaMGCAli9frsmTJ7vPeeedd2S329WvXz+dOnVKHTt21MSJExUdHa2VK1fq3nvv1aWXXqorr7yyzHs4HA7deuutaty4sTZt2qTs7OwiQZYkRUVFafny5WrSpIl27NihoUOHKioqShMmTFDfvn317bffavXq1fr4448lSTExMUWukZubq9TUVHXt2lVbtmzR4cOHNWTIEI0aNcojNF23bp3i4uK0bt06ZWRkqG/fvurQoYOGDh1a5ucp7vPlh4mffvqpzp8/r5EjR6pv375av369JKl///664oor9PLLL8tqtWr79u2qVauWJGnkyJHKy8vTZ599poiICH333XeKjIz0uY7S7N27V2vWrFFISIjP586bN08zZ87UX//6V7377rsaMWKErr76arVq1cqr87OzsyVJ9erV8/neviBQNAsCRQAAAAAASnTOIc3/5nyFruGUtDbLobVZviWTY9sFK8Tq3bGDBw/W008/rU8//VQ9evSQ5FrufNtttykmJkYxMTEaN26c+/gHHnhAa9as0dtvv+1VoPjxxx/r+++/15o1a9SkSRNJ0uzZs4s893DKlCnuPyckJGjcuHF66623NGHCBNWuXVuRkZHurruSvPHGGzpz5oxee+01RURESJJeeOEF9erVS08++aQaN24sSapbt65eeOEFWa1WXXbZZbr55puVnp5erkAxPT1dO3bs0J49exQfHy9Jeu2119S2bVtt2bJFnTt3VmZmpsaPH6/LLrtMkpSUlOQ+PzMzU7fddpuSk5MlSS1atPC5huLs2LFDkZGRstvtOnPmjCRp/vz5Pl/npptu0l/+8hdJri7SZ555RuvWrfMqUHQ4HBozZoy6d++uyy+/3Od7+4Ilz2ZBoAgAAAAAgOlddtll6tatm5YuXSpJysjI0Oeff660tDRJkt1u18yZM5WcnKx69eopMjJSa9asUWZmplfX37lzp+Lj491hoiR17dq1yHErVqxQ9+7dFRsbq8jISE2ZMsXrexS8V/v27d1hoiR1795dDofDYzBI27ZtZbVeTFzj4uJ0+PBhn+5V8J7x8fHuMFGS2rRpozp16mjnzp2SpLFjx2rIkCFKSUnRE088oR9//NF97IMPPqhZs2ape/fuevTRR0sdgjN79mxFRka6t9K+P61atdL27du1ZcsWTZw4UampqXrggQd8/nwFn6FpsVgUGxvr9fdq5MiR+vbbb/XWW2/5fF9f0aFoElm/1ddu9VDSrxGyGV0MAAAAAAB+plaQq1PQFyfznPrb93YVfHKiRdKQy6yKCil7CXPBe/siLS1NDzzwgF588UUtW7ZMl156qa6++mpJ0tNPP61nn31WCxYsUHJysiIiIjRmzBjl5eX5dpNSbNy4Uf3799eMGTOUmpqqmJgYvfXWW5o3b16l3aOg/OXG+SwWixyOcqxP99L06dN19913a+XKlfr3v/+tRx99VG+99ZZuueUWDRkyRKmpqVq5cqU++ugjzZkzR/PmzSs2/Lv//vt15513ul8XDGkLCwkJUWJioiTpiSee0M0336wZM2Zo5syZkqSgoCA5nZ7P6CzuOZLl/V6NGjVKH374oT777DPZbFWfHNGhaALPPy81e/UxXat1avb8w1qyxOiKAAAAAADwLxaLRSFW37b6tYPU8xKr8qNDi6Sel1hVv3aQT9fx5vmJBd15550KCgrSG2+8oddee02DBw92X+OLL75Q7969dc8996h9+/Zq0aKFfvjhB6+v3bp1a+3fv18HDhxw7/vyyy89jtmwYYOaNWumyZMnq1OnTkpKStK+ffs8jgkJCZG9jFWSrVu31tdff+0xUfiLL75QUFCQ18/881X+59u/f79733fffacTJ06oTZs27n0tW7bUQw89pI8++ki33nqrli1b5n4vPj5e999/v9577z09/PDDWrx4cbH3qlevnhITE91bcLD3gfWUKVM0d+5c/fLLL5Jck7gL/kzsdru+/fZbr69XEqfTqVGjRun999/XJ598oubNm1f4mt4gUPRzWVnSmDGS48KPyuEM0vDhrv0AAAAAAKBi2tcP0oi2weqXaNWItsFqX7/qo5LIyEj17dtXkyZN0oEDBzwm/SYlJWnt2rXasGGDdu7cqeHDh3tMMC5LSkqKWrZsqfvuu09ff/21Pv/8c02ePNnjmKSkJGVmZuqtt97Sjz/+qOeee07vv/++xzEJCQnas2ePtm/frqNHj+rs2bNF7tW/f3+FhYXpvvvu07fffqt169bpgQce0L333ut+fmJ52e12bd++3WPbuXOnUlJSlJycrP79+2vbtm3avHmzBgwYoKuvvlqdOnXSb7/9plGjRmn9+vXat2+fvvjiC23ZskWtW7eWJI0ZM0Zr1qzRnj17tG3bNq1bt879XmXq2rWr2rVrp9mzZ0uSrr32Wq1cuVIrV67U999/rxEjRujEiRMVvs/IkSP1+uuv64033lBUVJQOHjyogwcP6rfffqvwtUtDoOjndu+WCne22u1SRoYx9QAAAAAAUNNEh1jULCpI0T4sc66otLQ0/frrr0pNTfVYSjtlyhT97ne/U2pqqnr06KHY2Fj16dPH6+sGBQXp/fff12+//aYrr7xSQ4YM0eOPP+5xzJ///Gc99NBDGjVqlDp06KANGzZo6tSpHsfcdttt6tmzp6655ho1bNhQb775ZpF7hYeHa82aNTp+/Lg6d+6s22+/Xdddd51eeOEF374ZxTh16pSuuOIKj61Xr16yWCz617/+pbp16+qqq65SSkqKWrRooRUrVkiSrFarjh07pgEDBqhly5a68847deONN2rGjBmSXEHlyJEj1bp1a/Xs2VMtW7bUSy+9VOF6i/PQQw/pb3/7m/bv36/Bgwfrvvvuc4efLVq00DXXXFPhe7z88svKzs5Wjx49FBcX597yvx9VxeIsvIDbhHJychQTE6Ps7GxFR0cbXU6lysqSmjXzDBWtVmnvXqkalsQDAAAAAOCXzpw5oz179qh58+YKCwszuhzANEr6Z8eXfI0ORT9ns0mPPnrxtdXi0KJFhIkAAAAAAAAwBoGiCfTt6/oaqRztHTBNFybJAwAAAAAAANWOQNEErFbXV4skW+1jhtYCAAAAAACAwEagaAL5U8ntsromsgAAAAAAAAAGIVA0gfxA8byCCRQBAAAAACigBsyaBapVZfwzQ6BoAvlLngkUAQAAAABwsV74y3JeXp7BlQDmcvr0aUlSrVq1yn2N4MoqBlUnv0PRIauc5+2yGFsOAAAAAACGCw4OVnh4uI4cOaJatWopKIieKaA0TqdTp0+f1uHDh1WnTh13KF8eBIomUPDnaz/v5IcGAAAAAAh4FotFcXFx2rNnj/bt22d0OYBp1KlTR7GxsRW6BtmUCQQX+CmdP88PDQAAAAAASQoJCVFSUhLLngEv1apVq0KdifnIpkygYKDIIxQBAAAAALgoKChIYWFhRpcBBBQeMGACBYPj8+eNqwMAAAAAAAAgUDQBjw7F8xUf7Q0AAAAAAACUF4GiCRQcVEWHIgAAAAAAAIxEoGgCFotkDXJIIlAEAAAAAACAsQgUTSLY6lrqzFAWAAAAAAAAGIlA0SSC6VAEAAAAAACAHyBQNAlrkKtDkUARAAAAAAAARiJQNAmWPAMAAAAAAMAfECiahPXCT+q83WJsIQAAAAAAAAhoBIomERx8Yclzdq6UlWVwNQAAAAAAAAhUBIomEZz3myTJvjdTatZMWrLE4IoAAAAAAAAQiAgUzSArS9ZTJyRJ5xUsORzS8OF0KgIAAAAAAKDaESiawe7dCpZrvLNdVtc+u13KyDCwKAAAAAAAAAQiAkUzSEpyB4rnFezaZ7VKiYkGFgUAAAAAAIBARKBoBjabrA3qSroQKFqt0qJFks1mcGEAAAAAAAAINMFGFwDvBNeNko5K9roNpW/2EiYCAAAAAADAEHQomkTwhej3vDWUMBEAAAAAAACGIVA0CeuFWSzn7RZjCwEAAAAAAEBAI1A0ieBgV5BotxtcCAAAAAAAAAIagaJJWPOXPNOhCAAAAAAAAAMRKJpEfocigSIAAAAAAACMRKBoEsG1XF9Z8gwAAAAAAAAjESiahNVKhyIAAAAAAACMR6BoEsG1LgSKDovkdBpcDQAAAAAAAAIVgaJJ5AeKdlklh8PgagAAAAAAABCoCBRNwpo/lEXB0vnzBlcDAAAAAACAQEWgaBLBIQU6FAkUAQAAAAAAYBACRZNwP0ORDkUAAAAAAAAYiEDRJKzBrh8VgSIAAAAAAACMRKBoEh5DWc6dM7gaAAAAAAAABCoCRZOwWl1f6VAEAAAAAACAkQgUTSI42PWVQBEAAAAAAABGIlA0ifxAkSnPAAAAAAAAMBKBokmw5BkAAAAAAAD+gEDRJFjyDAAAAAAAAH9QrkDxxRdfVEJCgsLCwtSlSxdt3ry5xGN79Oghi8VSZLv55pvdxwwcOLDI+z179ixPaTUWS54BAAAAAADgD4J9PWHFihUaO3asFi5cqC5dumjBggVKTU3Vrl271KhRoyLHv/fee8rLy3O/PnbsmNq3b6877rjD47iePXtq2bJl7tehoaG+llajseQZAAAAAAAA/sDnDsX58+dr6NChGjRokNq0aaOFCxcqPDxcS5cuLfb4evXqKTY21r2tXbtW4eHhRQLF0NBQj+Pq1q1bvk9UQ3l0KJ47Z2wxAAAAAAAACFg+BYp5eXnaunWrUlJSLl4gKEgpKSnauHGjV9dYsmSJ7rrrLkVERHjsX79+vRo1aqRWrVppxIgROnbsWInXOHv2rHJycjy2mo5nKAIAAAAAAMAf+BQoHj16VHa7XY0bN/bY37hxYx08eLDM8zdv3qxvv/1WQ4YM8djfs2dPvfbaa0pPT9eTTz6pTz/9VDfeeKPsdnux15kzZ45iYmLcW3x8vC8fw5RY8gwAAAAAAAB/4PMzFCtiyZIlSk5O1pVXXumx/6677nL/OTk5We3atdOll16q9evX67rrritynUmTJmns2LHu1zk5OTU+VGQoCwAAAAAAAPyBTx2KDRo0kNVq1aFDhzz2Hzp0SLGxsaWem5ubq7feektpaWll3qdFixZq0KCBMjIyin0/NDRU0dHRHltNR4ciAAAAAAAA/IFPgWJISIg6duyo9PR09z6Hw6H09HR17dq11HPfeecdnT17Vvfcc0+Z98nKytKxY8cUFxfnS3k1Gs9QBAAAAAAAgD/wecrz2LFjtXjxYr366qvauXOnRowYodzcXA0aNEiSNGDAAE2aNKnIeUuWLFGfPn1Uv359j/2nTp3S+PHj9eWXX2rv3r1KT09X7969lZiYqNTU1HJ+rJqHJc8AAAAAAADwBz4/Q7Fv3746cuSIpk2bpoMHD6pDhw5avXq1e1BLZmamgoI8c8pdu3bpP//5jz766KMi17Narfrmm2/06quv6sSJE2rSpIluuOEGzZw5U6GhoeX8WDWPx5Lnc+eMLQYAAAAAAAABq1xDWUaNGqVRo0YV+9769euL7GvVqpWcTmexx9euXVtr1qwpTxkBxXPJ82/GFgMAAAAAAICA5fOSZxiDJc8AAAAAAADwBwSKJsGUZwAAAAAAAPgDAkWToEMRAAAAAAAA/oBA0SQ8n6FIoAgAAAAAAABjECiaBEueAQAAAAAA4A8IFE0iv0PxuOoq62iYscUAAAAAAAAgYBEomsTHH7u+fq82ajZriJYsMbYeAAAAAAAABCYCRRPIypJeeOHia4czSMOHu/YDAAAAAAAA1YlA0QR275YcDs99druUkWFMPQAAAAAAAAhcBIomkJQkBRX6SVmtUmKiMfUAAAAAAAAgcBEomoDNJj3yyMXXVotDixa59gMAAAAAAADViUDRJG67zfW1gY5o77DZSkszth4AAAAAAAAEJgJFk6hVy/U1SA7Zah8zthgAAAAAAAAELAJFk8gPFM+plnTunLHFAAAAAAAAIGARKJpESIjra55CpPPnjS0GAAAAAAAAAYtA0SQ8OhQJFAEAAAAAAGAQAkWTIFAEAAAAAACAPyBQNIn8QNGpINnz7MYWAwAAAAAAgIBFoGgS+YGixEwWAAAAAAAAGIdA0SQ8AsU8p3GFAAAAAAAAIKARKJpEwUAx75zFuEIAAAAAAAAQ0AgUTcJqlSwWV2ciHYoAAAAAAAAwCoGiSVgsUi2rQ5J07sgJKSvL2IIAAAAAAAAQkAgUTaSWXNNYzn3zndSsmbRkicEVAQAAAAAAINAQKJpFVpZqnf9NknROtSSHQxo+nE5FAAAAAAAAVCsCRbPYvftih6IuTGix26WMDAOLAgAAAAAAQKAhUDSLpCR3oJinENc+q1VKTDSwKAAAAAAAAAQaAkWzsNkUEl1b0oUORatVWrRIstkMLgwAAAAAAACBJNjoAuC9WtFhUo50rpFN2voPwkQAAAAAAABUOzoUTaTWhUcnngsKJUwEAAAAAACAIQgUTcQdKJ4ztg4AAAAAAAAELgJFE3EHiuctxhYCAAAAAACAgEWgaCK1QlxBIh2KAAAAAAAAMAqBoomEhLi+5p3nxwYAAAAAAABjkEyZiLtDkSXPAAAAAAAAMAiBoom4A0VHkOR0GlwNAAAAAAAAAhGBoonUCnH9uM6pFg9SBAAAAAAAgCEIFE2kVuiFDkXVkvLyDK4GAAAAAAAAgYhA0URqhRboUCRQBAAAAAAAgAEIFE0k5EKHYp5CCBQBAAAAAABgCAJFE6lViyXPAAAAAAAAMBaBoonUquX6ylAWAAAAAAAAGIVA0UQ8AkU6FAEAAAAAAGAAAkUTIVAEAAAAAACA0QgUTYRAEQAAAAAAAEYjUDSRkBDXV6Y8AwAAAAAAwCgEiibCUBYAAAAAAAAYjUDRRFjyDAAAAAAAAKMRKJoIgSIAAAAAAACMRqBoIgSKAAAAAAAAMBqBookQKAIAAAAAAMBoBIomkh8o/qI4ZR0MNrYYAAAAAAAABCQCRRPZuNH19Ut1U7Oxt2rJEmPrAQAAAAAAQOAhUDSJrCxp2bKLrx3OIA0f7toPAAAAAAAAVBcCRZPYvVtyOj332e1SRoYx9QAAAAAAACAwESiaRFKSZLF47rNapcREY+oBAAAAAABAYCJQNAmbTRoz5uJrq8WhRYtc+wEAAAAAAIDqQqBoIn36uL7GK1N7xyxQWpqh5QAAAAAAACAAESiaSGio66tVdtnCjhpbDAAAAAAAAAISgaKJ5AeKZxUq5eUZWwwAAAAAAAACEoGiieQHimcURqAIAAAAAAAAQxAomkhYmOsrHYoAAAAAAAAwCoGiiXgseT53zthiAAAAAAAAEJAIFE0kP1C0K1jn92ZJWVnGFgQAAAAAAICAU65A8cUXX1RCQoLCwsLUpUsXbd68ucRje/ToIYvFUmS7+eab3cc4nU5NmzZNcXFxql27tlJSUrR79+7ylFaj5QeKknT2k/9IzZpJS5YYVxAAAAAAAAACjs+B4ooVKzR27Fg9+uij2rZtm9q3b6/U1FQdPny42OPfe+89HThwwL19++23slqtuuOOO9zHPPXUU3ruuee0cOFCbdq0SREREUpNTdWZM2fK/8lqoLCjFzsSzypUcjik4cPpVAQAAAAAAEC18TlQnD9/voYOHapBgwapTZs2WrhwocLDw7V06dJij69Xr55iY2Pd29q1axUeHu4OFJ1OpxYsWKApU6aod+/eateunV577TX98ssv+uc//1mhD1fTBO/ZrSDZJV0IFCXJbpcyMgysCgAAAAAAAIHEp0AxLy9PW7duVUpKysULBAUpJSVFGzdu9OoaS5Ys0V133aWIiAhJ0p49e3Tw4EGPa8bExKhLly4lXvPs2bPKycnx2AJCUpJCdVZSgUDRapUSEw0sCgAAAAAAAIHEp0Dx6NGjstvtaty4scf+xo0b6+DBg2Wev3nzZn377bcaMmSIe1/+eb5cc86cOYqJiXFv8fHxvnwM87LZ3M9RPKMwV5i4aJFksxlbFwAAAAAAAAJGtU55XrJkiZKTk3XllVdW6DqTJk1Sdna2e9u/f38lVej/wsJdP7Kz8UnS3r1SWpqxBQEAAAAAACCg+BQoNmjQQFarVYcOHfLYf+jQIcXGxpZ6bm5urt566y2lFQrA8s/z5ZqhoaGKjo722AJFaIhTknTWGk5nIgAAAAAAAKqdT4FiSEiIOnbsqPT0dPc+h8Oh9PR0de3atdRz33nnHZ09e1b33HOPx/7mzZsrNjbW45o5OTnatGlTmdcMRPlLns+eNbYOAAAAAAAABKZgX08YO3as7rvvPnXq1ElXXnmlFixYoNzcXA0aNEiSNGDAADVt2lRz5szxOG/JkiXq06eP6tev77HfYrFozJgxmjVrlpKSktS8eXNNnTpVTZo0UZ8+fcr/yWoo9zMUz1qMLQQAAAAAAAAByedAsW/fvjpy5IimTZumgwcPqkOHDlq9erV7qEpmZqaCgjwbH3ft2qX//Oc/+uijj4q95oQJE5Sbm6thw4bpxIkT+sMf/qDVq1crLCysHB+pZsv/ltChCAAAAAAAACNYnE6n0+giKionJ0cxMTHKzs6u8c9T/GPnM/rPV2F6N6Sfbjv7ptHlAAAAAAAAoAbwJV+r1inPqLjQ2q6lzmfzLJL5s2AAAAAAAACYDIGiyYSGuX5kZxQm5eUZXA0AAAAAAAACDYGiyYSFu35kZxUqnTljcDUAAAAAAAAINASKJhNKoAgAAAAAAAADESiaTGjohWcoEigCAAAAAADAAASKJhMa6vp6RmEEigAAAAAAAKh2BIomExbm+kqHIgAAAAAAAIxAoGgy+R2KBIoAAAAAAAAwAoGiyXgEir/9ZmwxAAAAAAAACDgEiibDMxQBAAAAAABgJAJFk8l/huI+XaKsLGNrAQAAAAAAQOAhUDSZbdtcXz/WDWo2LFVLlhhbDwAAAAAAAAILgaKJZGVJb7558bXDadHw4aJTEQAAAAAAANWGQNFEdu+WnE7PfXa7lJFhTD0AAAAAAAAIPASKJpKUJFksnvusVikx0Zh6AAAAAAAAEHgIFE3EZpNGj7742mpxaNEi134AAAAAAACgOhAomsytt7q+2pSpvaOfUVqasfUAAAAAAAAgsBAomkx4eP6fLLKFHDayFAAAAAAAAAQgAkWTyQ8UTyvcNaWFEc8AAAAAAACoRgSKJuMRKL7/vtSsmbRkibFFAQAAAAAAIGAQKJpM+IlfJElnVFsOWSSHQxo+nE5FAAAAAAAAVAsCRZMJ/3m3+8+/qbbrD3a7lJFhUEUAAAAAAAAIJASKJlP78kvdfz6tC+ufrVYpMdGgigAAAAAAABBICBRNJugSm8KseZIuBIpWq7RokWSzGVwZAAAAAAAAAkGw0QXAd+Hh0pmT0ulLWktffEGYCAAAAAAAgGpDh6IJhYc5JV3oUCRMBAAAAAAAQDUiUDShiPALgeJpgwsBAAAAAABAwCFQNKHwC7NYcn/jxwcAAAAAAIDqRSJlQuERFknS6TP8+AAAAAAAAFC9SKRMKDzS9WM7bQ+R8vIMrgYAAAAAAACBhEDRhMKjrJIuDGXJzTW4GgAAAAAAAAQSAkUTcncoEigCAAAAAACgmhEomlD+UBYCRQAAAAAAAFQ3AkUTIlAEAAAAAACAUQgUTSg/UNylVsrac87YYgAAAAAAABBQCBRNaOdO19d3dYea3XGlliwxth4AAAAAAAAEDgJFk8nKkv7f/7v42uG0aPhw134AAAAAAACgqhEomszu3ZLT6bnPbpcyMoypBwAAAAAAAIGFQNFkkpIki8Vzn9UqJSYaUw8AAAAAAAACC4Giydhs0gMPXHxttdi16InjstmMqwkAAAAAAACBg0DRhG6/3fW1qfZrr7OZ0iY2FJNZAAAAAAAAUB0IFE0o+rdDkiS7gmXTz5LDISazAAAAAAAAoDoQKJpQ9NGfJEk5ir64k8ksAAAAAAAAqAYEiiYUndxMknRaETovq2snk1kAAAAAAABQDQgUTSiqVRP3n08qyhUmLlokJrMAAAAAAACgqgUbXQB8FxIihday6+w5q3KSOqnuJ8sIEwEAAAAAAFAt6FA0qegIuyQpxxFJmAgAAAAAAIBqQ6BoUtGRDklSTo7BhQAAAAAAACCgECiaVPSFAc85p/gRAgAAAAAAoPqQRplUdB3Xj+7kb1bJbje4GgAAAAAAAAQKAkWTiqpjlSTlKFo6edLgagAAAAAAABAoCBRNKvpCoLhNv1PW96cMrgYAAAAAAACBgkDRpH7+2fX1Zf1Fzbo31ZIlxtYDAAAAAACAwECgaEJZWdJnn1187XBYNHy4az8AAAAAAABQlQgUTWj3bsnp9Nxnt0sZGcbUAwAAAAAAgMBBoGhCSUmSxeK5z2qVEhONqQcAAAAAAACBg0DRhGw2afhV37lfW3Vei+75XDabgUUBAAAAAAAgIBAomlFWlu747EFJ0iXaq71KUNrr1/AQRQAAAAAAAFQ5AkUz2r1b9Z1HJElnFSabfuYhigAAAAAAAKgWBIpmlJSkepYTkqRjqi+nxEMUAQAAAAAAUC0IFM3IZlP9F2ZIks6rlk4pSlq0SDxEEQAAAAAAAFWNQNGkao8YqNDg85KkY22vktLSDK4IAAAAAAAAgYBA0aQsFql+Hbsk6XhOsMHVAAAAAAAAIFCUK1B88cUXlZCQoLCwMHXp0kWbN28u9fgTJ05o5MiRiouLU2hoqFq2bKlVq1a5358+fbosFovHdtlll5WntIBSr65TknTsV3JhAAAAAAAAVA+fW9tWrFihsWPHauHCherSpYsWLFig1NRU7dq1S40aNSpyfF5enq6//no1atRI7777rpo2bap9+/apTp06Hse1bdtWH3/88cXCgum6K0tElCtI3H0qVtefPy/xPQMAAAAAAEAV8zmBmj9/voYOHapBgwZJkhYuXKiVK1dq6dKleuSRR4ocv3TpUh0/flwbNmxQrVq1JEkJCQlFCwkOVmxsrK/lBKwlS6RN21zfz1F6QaEv5CptTJTBVQEAAAAAAKCm82mtbF5enrZu3aqUlJSLFwgKUkpKijZu3FjsOR988IG6du2qkSNHqnHjxrr88ss1e/Zs2e12j+N2796tJk2aqEWLFurfv78yMzNLrOPs2bPKycnx2AJJVpY0bJgkWSRJTgVp+MORysoytCwAAAAAAAAEAJ8CxaNHj8put6tx48Ye+xs3bqyDBw8We85PP/2kd999V3a7XatWrdLUqVM1b948zZo1y31Mly5dtHz5cq1evVovv/yy9uzZoz/+8Y86efJksdecM2eOYmJi3Ft8fLwvH8P0du+WHA7PfXaHRRkZxtQDAAAAAACAwFHl0zwcDocaNWqkV155RR07dlTfvn01efJkLVy40H3MjTfeqDvuuEPt2rVTamqqVq1apRMnTujtt98u9pqTJk1Sdna2e9u/f39Vfwy/kpQkBRX6yVl1Xolb3jSmIAAAAAAAAAQMnwLFBg0ayGq16tChQx77Dx06VOLzD+Pi4tSyZUtZrVb3vtatW+vgwYPKy8sr9pw6deqoZcuWyiih5S40NFTR0dEeWyCx2aRXnjyuIOUvG3dqkYbLNulese4ZAAAAAAAAVcmnQDEkJEQdO3ZUenq6e5/D4VB6erq6du1a7Dndu3dXRkaGHAXW6P7www+Ki4tTSEhIseecOnVKP/74o+Li4nwpL6Ckdfxab+sOSVKC9ipNSyW7Xax7BgAAAAAAQFXyecnz2LFjtXjxYr366qvauXOnRowYodzcXPfU5wEDBmjSpEnu40eMGKHjx49r9OjR+uGHH7Ry5UrNnj1bI0eOdB8zbtw4ffrpp9q7d682bNigW265RVarVf369auEj1hDJSWpneV/kqQjaujaZ7VKiYkGFgUAAAAAAICaLtjXE/r27asjR45o2rRpOnjwoDp06KDVq1e7B7VkZmYqqMAD/uLj47VmzRo99NBDateunZo2barRo0dr4sSJ7mOysrLUr18/HTt2TA0bNtQf/vAHffnll2rYsGElfMQaymZT3PN/lUZJuYrUKUUqctEC13poAAAAAAAAoIpYnE6n0+giKionJ0cxMTHKzs4OuOcpRoXl6dTZEP3QureSvvuX0eUAAAAAAADAhHzJ16p8yjOqVoO6rmdTfnO4scGVAAAAAAAAIBAQKJrYkiXS3oOhkqQ7ji3UksWOMs4AAAAAAAAAKoZA0aSysqRhwyTJIklyKkjDR1iUlWVoWQAAAAAAAKjhCBRNavduyVGoIdFutygjw5h6AAAAAAAAEBgIFE0qKUkKKvTTs+q8Ere8aUxBAAAAAAAACAgEiiZls0mvPHlcQbJf2OPUIg2XbdK9Yt0zAAAAAAAAqgqBoomldfxaK3WTJKmejilNSyW7Xax7BgAAAAAAQFUhUDSzpCR1sXwlSTquBjqt2pLVKiUmGlwYAAAAAAAAaioCRTOz2VTnlacUoZOSpM3qLC1a5FoPDQAAAAAAAFSBYKMLQMUstaQpV05J0rVap8UKUprBNQEAAAAAAKDmokPRxLKypGHDJMkiSXIqSMOHOZnJAgAAAAAAgCpDoGhiu3dLDofnPrvDooxnVxpTEAAAAAAAAGo8AkUTS0qSgoKcHvusOq/E+X8RbYoAAAAAAACoCgSKJmazSa+M3aUg2S/scWqRhsvmyJQyMgytDQAAAAAAADUTgaLJpY2O1Cb9/sIrh67RJ5LVKiUmGloXAAAAAAAAaiYCRbOz2bR9wHxJTklWJSlDS+5Z52pfBAAAAAAAACqZxel0Oss+zL/l5OQoJiZG2dnZio6ONrqcapWVJTVr5jmcxWp1au9eC5kiAAAAAAAAvOJLvkaHoskVO+nZzqRnAAAAAAAAVA0CRZNj0jMAAAAAAACqE4GiyRU36XmOHmHSMwAAAAAAAKoEgWINkDY6UlM068Irix7Rk1piGcKkZwAAAAAAAFQ6AsUaIEs2zbJMdb92yKrhWqQsMZUFAAAAAAAAlYtAsQbYvVtyOD1/lHZnEINZAAAAAAAAUOkIFGuA4gazBDGYBQAAAAAAAFWAQLEGyB/MYpHDvc+pIK1xpDCYBQAAAAAAAJWKQLGGSL0zRhZd7FJ0Ksj1HMWIVgZWBQAAAAAAgJqGQLGG2H0qTg5ZPfbZFayM3DiDKgIAAAAAAEBNRKBYQ7ieo+i5L0jnlbjlTWMKAgAAAAAAQI1EoFhD2GzSK08eL/ocxYmfMJgFAAAAAAAAlYZAsQZJveT7os9RdL6srI37DawKAAAAAAAANQmBYg2yW0nFP0dRiQZVBAAAAAAAgJqGQLEGSerWUEEWh8e+IJ1X4t6PDaoIAAAAAAAANQ2BYg1is0mvPHWC5ygCAAAAAACgyhAo1jA8RxEAAAAAAABViUCxhinxOYqfZBpUEQAAAAAAAGoSAsUaprjnKEpOfbVoK8ueAQAAAAAAUGEEijWMzSY9MewnqcCyZ8miR5yzWfYMAAAAAACACiNQrIE6XRsjyeKxz65gZSjRmIIAAAAAAABQYxAo1kAlLnt++ydD6gEAAAAAAEDNQaBYA9ls0hN/zVaRZc/vdlTWlgNGlQUAAAAAAIAagECxhupUb6+KXfb8xSFD6gEAAAAAAEDNQKBYQyX9MVZBshfa69RXH58wohwAAAAAAADUEASKNZStc5yeuOkzFVn2vPIPLHsGAAAAAABAuREo1mCdrqsjlj0DAAAAAACgMhEo1mAsewYAAAAAAEBlI1CswUpa9jyRZc8AAAAAAAAoJwLFGq64Zc8OBevZeecMqQcAAAAAAADmRqBYwyX9MVaWIsuepWfetikry4CCAAAAAAAAYGoEijWcrXOcHr5qa5H9dmeQMjYeMaAiAAAAAAAAmBmBYgAYPfJ88cNZXtxkSD0AAAAAAAAwLwLFAGDrdome0CMqPJzlkU97MpwFAAAAAAAAPiFQDAQ2mzrdeakKD2exK1gZXxwypiYAAAAAAACYEoFigEga17v4Zc8fnzCiHAAAAAAAAJgUgWKAsHWO0xM3fabCy54nrvwDy54BAAAAAADgNQLFANLpujoqvOzZoWA9O++cIfUAAAAAAADAfAgUA0jSH2NlKbLsWXrmbZuysgwoCAAAAAAAAKZDoBhAbJ3j9PBVW4vstzuDlLHxiAEVAQAAAAAAwGwIFAPM6JHnix/O8uImQ+oBAAAAAACAuRAoBhhbt0v0hB5R4eEsj3zak+EsAAAAAAAAKBOBYqCx2dTpzktVeDiLXcHK+OKQMTUBAAAAAADANAgUA1DkvbfIs0NRkpyKSIwzohwAAAAAAACYCIFiADp1OkiFOxQli95eGW5EOQAAAAAAADARAsUAlKTdshQZzCI9syhCWVkGFAQAAAAAAADTIFAMQLZul+hhzS+y3+4MUsbGIwZUBAAAAAAAALMoV6D44osvKiEhQWFhYerSpYs2b95c6vEnTpzQyJEjFRcXp9DQULVs2VKrVq2q0DVRATabRg8/q6AiXYpOffVJjiElAQAAAAAAwBx8DhRXrFihsWPH6tFHH9W2bdvUvn17paam6vDhw8Uen5eXp+uvv1579+7Vu+++q127dmnx4sVq2rRpua+JirNNGagnNEmew1ksmriwOcueAQAAAAAAUCKL0+ksPO63VF26dFHnzp31wgsvSJIcDofi4+P1wAMP6JFHHily/MKFC/X000/r+++/V61atSrlmoXl5OQoJiZG2dnZio6O9uXjBLR1w9/Sta/cVWT/uPtP6umXowyoCAAAAAAAAEbwJV/zqUMxLy9PW7duVUpKysULBAUpJSVFGzduLPacDz74QF27dtXIkSPVuHFjXX755Zo9e7bsdnu5r3n27Fnl5OR4bPBd0nWXMJwFAAAAAAAAPvEpUDx69KjsdrsaN27ssb9x48Y6ePBgsef89NNPevfdd2W327Vq1SpNnTpV8+bN06xZs8p9zTlz5igmJsa9xcfH+/IxcAHDWQAAAAAAAOCrKp/y7HA41KhRI73yyivq2LGj+vbtq8mTJ2vhwoXlvuakSZOUnZ3t3vbv31+JFQcQhrMAAAAAAADARz4Fig0aNJDVatWhQ4c89h86dEixsbHFnhMXF6eWLVvKarW697Vu3VoHDx5UXl5eua4ZGhqq6Ohojw3lw3AWAAAAAAAA+MKnQDEkJEQdO3ZUenq6e5/D4VB6erq6du1a7Dndu3dXRkaGHA6He98PP/yguLg4hYSElOuaqEQ2mzoN+50ki8duh4L07OMnjakJAAAAAAAAfsvnJc9jx47V4sWL9eqrr2rnzp0aMWKEcnNzNWjQIEnSgAEDNGnSJPfxI0aM0PHjxzV69Gj98MMPWrlypWbPnq2RI0d6fU1UrZKGs8xfyHAWAAAAAAAAeAr29YS+ffvqyJEjmjZtmg4ePKgOHTpo9erV7qEqmZmZCgq6mFPGx8drzZo1euihh9SuXTs1bdpUo0eP1sSJE72+JqpW/nCWuRrvsT+/S/Hpl6MMqgwAAAAAAAD+xuJ0Op1lH+bfcnJyFBMTo+zsbJ6nWE5Z98/SJYsmySmrx/4gObRvf5BsNoMKAwAAAAAAQJXzJV+r8inPMAfblIF6WPOL7OdZigAAAAAAACiIQBEuNptGDz9b7LMUn3klkmcpAgAAAAAAQBKBIgpwdSk+U2S/3WFRRoYBBQEAAAAAAMDvECjiIptNo/8aoaAiXYpOffXxCSMqAgAAAAAAgJ8hUIQHW8plekITJRWc1WPRxMejWfYMAAAAAAAAAkUUkpSkTtomyeKxm+EsAAAAAAAAkAgUUZjNpqTh1xY7nGX+wgi6FAEAAAAAAAIcgSKKcA1nmV9kP12KAAAAAAAAIFBEUTabRg8/W3yX4qJIuhQBAAAAAAACGIEiiuXqUnymyH6H06JnnzWgIAAAAAAAAPgFAkUUz2bT6L9GFN+lOM9JlyIAAAAAAECAIlBEiWwpl+lhzSuyny5FAAAAAACAwEWgiJIlJWm0nqdLEQAAAAAAAG4EiiiZzSbbuLvoUgQAAAAAAICbxel0Oo0uoqJycnIUExOj7OxsRUdHG11OzZKVpaz4rrpEe+WU1eOtIItT+zItstkMqg0AAAAAAACVwpd8jQ5FlI4uRQAAAAAAABRAhyLKRpciAAAAAABAjUaHIioXXYoAAAAAAAC4gA5FeCcrS1mXdNMlzj1FuxSDpH37RJciAAAAAACASdGhiMpns8n25APFdyk6RJciAAAAAABAgCBQhPc6ddJoPSeL7EXeeuYZKSvLgJoAAAAAAABQrQgU4b2kJNksvxTbpWi3SxkZBtQEAAAAAACAakWgCO/ZbNLDD+tOvSOp8KM3nYqIMKIoAAAAAAAAVCcCRfhm9GidUpQkS6E3LHp76UkjKgIAAAAAAEA1IlCEb2w2JQ2/ttjnKM5fFMlzFAEAAAAAAGo4AkX4zJaWWvy0Z6eFac8AAAAAAAA1HIEifHfqVInTnufPZ9ozAAAAAABATUagCN+VMu3Z4RBdigAAAAAAADUYgSJ8d2HaM12KAAAAAAAAgYdAEeUzejRdigAAAAAAAAGIQBHlQ5ciAAAAAABAQCJQRPnRpQgAAAAAABBwCBRRfnQpAgAAAAAABBwCRVQMXYoAAAAAAAABhUARFUOXIgAAAAAAQEAhUETF0aUIAAAAAAAQMAgUUXF0KQIAAAAAAAQMAkVUDroUAQAAAAAAAgKBIioHXYoAAAAAAAABgUARlYcuRQAAAAAAgBqPQBGVhy5FAAAAAACAGo9AEZWrjC7FWbMMqAkAAAAAAACVhkARlauMLsVFi6S5cw2oCwAAAAAAAJWCQBGVr5QuRUmaMIGlzwAAAAAAAGZFoIjKV0aXotPJgBYAAAAAAACzIlBE1bjQpfikJkpyFnmbAS0AAAAAAADmRKCIqnGhS3G85mm4FhZ52+GgSxEAAAAAAMCMLE6ns2j7mMnk5OQoJiZG2dnZio6ONroc5MvKki65RFnOJrpE++SU1ePtoCBp3z5X9ggAAAAAAADj+JKv0aGIqnOhS9Gmn4sd0OJwSLNmGVAXAAAAAAAAyo1AEVVr9GjJYilxQMuiRdLcuQbUBQAAAAAAgHIhUETVKqNLUZImTmRACwAAAAAAgFkQKKLqldGl6HBIGRkG1AUAAAAAAACfESii6hXoUpyk2ZIKzwFyKiLCiMIAAAAAAADgKwJFVI8LXYop+kSSpdCbFi1ZYkRRAAAAAAAA8BWBIqqHzSY9+aSStLuE4SxOhrMAAAAAAACYAIEiqs/48bIN/1MJw1ksmjCB4SwAAAAAAAD+jkAR1SstrcThLE6n9OyzBtQEAAAAAAAArxEoonqdOiWbftaTmqiiw1mk+fPpUgQAAAAAAPBnBIqoXklJksWi8Zqn4VpY5G2HQ5o1y4C6AAAAAAAA4BUCRVQvm016+GFJ0hQ9XsKAFjGgBQAAAAAAwE8RKKL6jR4tWSyy6ecSBrSIAS0AAAAAAAB+ikAR1a9Al2JpA1pY+gwAAAAAAOB/CBRhjAJdiiUNaGHpMwAAAAAAgP8pV6D44osvKiEhQWFhYerSpYs2b95c4rHLly+XxWLx2MLCwjyOGThwYJFjevbsWZ7SYBY2m/Tkk5JU4oAWiaXPAAAAAAAA/sbnQHHFihUaO3asHn30UW3btk3t27dXamqqDh8+XOI50dHROnDggHvbt29fkWN69uzpccybb77pa2kwm/HjpeHDJZU8oIWlzwAAAAAAAP7F50Bx/vz5Gjp0qAYNGqQ2bdpo4cKFCg8P19KlS0s8x2KxKDY21r01bty4yDGhoaEex9StW9fX0mBGU6aw9BkAAAAAAMBEfAoU8/LytHXrVqWkpFy8QFCQUlJStHHjxhLPO3XqlJo1a6b4+Hj17t1b//vf/4ocs379ejVq1EitWrXSiBEjdOzYsRKvd/bsWeXk5HhsMKkCA1pY+gwAAAAAAOD/fAoUjx49KrvdXqTDsHHjxjp48GCx57Rq1UpLly7Vv/71L73++utyOBzq1q2bsgqkQz179tRrr72m9PR0Pfnkk/r000914403ym4vugRWkubMmaOYmBj3Fh8f78vHgL+5MKBFYukzAAAAAACAv7M4nc6ia0xL8Msvv6hp06basGGDunbt6t4/YcIEffrpp9q0aVOZ1zh37pxat26tfv36aebMmcUe89NPP+nSSy/Vxx9/rOuuu67I+2fPntXZs2fdr3NychQfH6/s7GxFR0d7+3HgT8aPd69rfloPa4KelmQpctjTT0vjxlVzbQAAAAAAADVcTk6OYmJivMrXfOpQbNCggaxWqw4dOuSx/9ChQ4qNjfXqGrVq1dIVV1yhjIyMEo9p0aKFGjRoUOIxoaGhio6O9thgcgW6FFn6DAAAAAAA4L98ChRDQkLUsWNHpaenu/c5HA6lp6d7dCyWxm63a8eOHYqLiyvxmKysLB07dqzUY1DD2GzSk0+6X7L0GQAAAAAAwD/5POV57NixWrx4sV599VXt3LlTI0aMUG5urgYNGiRJGjBggCZNmuQ+/rHHHtNHH32kn376Sdu2bdM999yjffv2aciQIZJcA1vGjx+vL7/8Unv37lV6erp69+6txMREpaamVtLHhCmMHy8NHy5JTH0GAAAAAADwU8G+ntC3b18dOXJE06ZN08GDB9WhQwetXr3aPaglMzNTQUEXc8pff/1VQ4cO1cGDB1W3bl117NhRGzZsUJs2bSRJVqtV33zzjV599VWdOHFCTZo00Q033KCZM2cqNDS0kj4mTGPKFOmVVySnU+M1Tz/qUi3SiCKHTZgg3XWXq7ERAAAAAAAA1cenoSz+ypeHRsIECgxoyVJTXaJ9cspa5LDhw6WFxT9qEQAAAAAAAD6osqEsQLUoMKCFpc8AAAAAAAD+hUAR/qfQgBamPgMAAAAAAPgPAkX4pwIDWqTSpz4/+2x1FgYAAAAAABDYCBThv6ZM8Wrp89y5dCkCAAAAAABUFwJF+C+bTXr4YffL8Zqn/vq/Yg99/PHqKgoAAAAAACCwESjCvxUY0CJJf9aHxR62aBFdigAAAAAAANWBQBH+rdCAlm7aIMlR5DCnU5o1qxrrAgAAAAAACFAEivB/BQa02PSzntIEFfcsxUWLXI9dBAAAAAAAQNUhUIQ5FBjQMl7zNFwLiz3s8cddQ1oAAAAAAABQNQgUYQ6Flj5P0eOyyF7soRMm8DxFAAAAAACAqkKgCPMYP17q31+Sa+nzk5qo4pY+8zxFAAAAAACAqkOgCHP585/dfxyveZqsWeJ5igAAAAAAANWHQBHm0q2bx8tZmlbq8xQJFQEAAAAAACoXgSLMxWaTxo3z2FXa8xQZ0gIAAAAAAFC5CBRhPqNHuyc+S6U/T1FiSAsAAAAAAEBlIlCE+RSa+CyV/jxFhrQAAAAAAABUHgJFmNP48dLw4R67ZmkaQ1oAAAAAAACqGIEizGvKFI+lzxJDWgAAAAAAAKoagSLMq5ilz1LZQ1oIFQEAAAAAAMqPQBHmVszS57KGtDD5GQAAAAAAoPwIFGF+xSx9Lm1Ii8TkZwAAAAAAgPIiUIT5lbD0ubQhLUx+BgAAAAAAKB8CRdQMxSx9lpj8DAAAAAAAUNkIFFFzFLP0WSp78jPPUwQAAAAAAPAegSJqjhKWPkv5k58dxb43fjzPUwQAAAAAAPAWgSJqlvHjpcmTi+x2TX6eoJKGtEyaVMV1AQAAAAAA1BAEiqh5Zs0q9nmK4zVP/fV/xZ7y+us8TxEAAAAAAMAbBIqomUp4nuIT+qtK6lJ8/HFCRQAAAAAAgLIQKKJmKuF5ijb9rKc0XoSKAAAAAAAA5UOgiJpr/PgSlz5P1iwRKgIAAAAAAPiOQBE1WwlLn2dpGqEiAAAAAABAORAoomYrYemzRKgIAAAAAABQHgSKqPnGj5cmTy72rVmapsm/Ty/xVEJFAAAAAAAATwSKCAyzZpUcKn55vSY/kF3iqYSKAAAAAAAAFxEoInDMmiX171/8W7+OKilvlESoCAAAAAAAkI9AEYHlz38ufv/rr2tWnbmEigAAAAAAAGUgUERg6dat5PcmTNCs+7MIFQEAAAAAAEpBoIjAYrNJTz1V/HtOpzRrVmmPW5REqAgAAAAAAAJbsNEFANVu/HgpO9uVDBa2aJHUoIFmzZolqfhD8vfn5EjPPVeFdQIAAAAAAPghAkUEplmzpKNHXQFiYRdSxLJCxeefl376Sfrww6oqEgAAAAAAwP+w5BmBa8oUyWIp/r0L65rLWv68cqX04INVUx4AAAAAAIA/IlBE4LLZpCefLPn9xx+X5s4tM1R8/nmeqQgAAAAAAAIHgSIC2/jxpaeFEyZIWVmaNUt64IGSD2NQCwAAAAAACBQEikBpLYgXJj9LrgEsN99c8mUef1y65x4pK6sKagQAAAAAAPATBIqAVHqouGiRu/3www9L71T8+9+l+Hjp6aeroEYAAAAAAAA/QKAI5Js1Sxo+vPj3Cqxpfu650ldJS66V0iyBBgAAAAAANRGBIlCQF5OfpdIbGgsezhJoAAAAAABQ0xAoAgV5M/nZh1CRJdAAAAAAAKCmIVAECitr8nOhUNGbsHDCBLoVAQAAAABAzUCgCBSnrPbDAqHiuHHS/v2uwLA0dCsCAAAAAICagEARKIk3oeLcuZJcK6X/7//KXgItMbAFAAAAAACYG4EiUJqyQsXx4z3WMXu7BPrxx6UHH6yE+gAAAAAAAKoZgSJQlrJCxUmTPF56uwT6+eel3/+e5yoCAAAAAABzIVAEvDFrltS/f/Hvvf56kTXM+Uugy+pW3LSJ5yoCAAAAAABzIVAEvPXEEyW/V2BIS0HedisyBRoAAAAAAJgFgSLgLZtNeuqpkt8vIVTM71Z84IHSL58/BXr4cIJFAAAAAADgvwgUAV+MH1/25OcSRjg/95x0881l3+KVV1gGDQAAAAAA/BeBIuCrsoa0lBIqfvhh6acWxDJoAAAAAADgjwgUgfKoQKg4a5Z3z1WUWAYNAAAAAAD8D4EiUF4VCBW9nQKdL38ZNMEiAAAAAAAwGoEiUBEVCBWli1Og77/fu9sRLAIAAAAAAKMRKAIVVcFQ0WaTXn7Z+2XQEoNbAAAAAACAcQgUgcrgTahYxoQVX5dBSwxuAQAAAAAA1Y9AEagsZYWK+RNWykgMfV0GzeAWAAAAAABQncoVKL744otKSEhQWFiYunTpos2bN5d47PLly2WxWDy2sLAwj2OcTqemTZumuLg41a5dWykpKdq9e3d5SgOMVVaoKLnaCktZAi15LoP29fmK/ftLb79NuAgAAAAAAKqGz4HiihUrNHbsWD366KPatm2b2rdvr9TUVB0+fLjEc6Kjo3XgwAH3tm/fPo/3n3rqKT333HNauHChNm3apIiICKWmpurMmTO+fyLAaN6EimU8VzFfeZ6v+MYbUt++dC0CAAAAAICq4XOgOH/+fA0dOlSDBg1SmzZttHDhQoWHh2vp0qUlnmOxWBQbG+veGjdu7H7P6XRqwYIFmjJlinr37q127drptdde0y+//KJ//vOf5fpQgOG8DRXnzvXqcuV5vqJE1yIAAAAAAKh8PgWKeXl52rp1q1JSUi5eIChIKSkp2rhxY4nnnTp1Ss2aNVN8fLx69+6t//3vf+739uzZo4MHD3pcMyYmRl26dCnxmmfPnlVOTo7HBvidWbPKTgDHj/cp5fP1+Yr56FoEAAAAAACVxadA8ejRo7Lb7R4dhpLUuHFjHTx4sNhzWrVqpaVLl+pf//qXXn/9dTkcDnXr1k1ZFxKN/PN8ueacOXMUExPj3uLj4335GED1yU8AS1uvPGiQTwlfeZ6vWFDBrkWCRQAAAAAA4Ksqn/LctWtXDRgwQB06dNDVV1+t9957Tw0bNtSiRYvKfc1JkyYpOzvbve3fv78SKwYqWf565f79i3//44+9mv5c3GULBosWi29lvfEGy6EBAAAAAIDvfAoUGzRoIKvVqkOHDnnsP3TokGJjY726Rq1atXTFFVcoIyNDktzn+XLN0NBQRUdHe2yA33viidLf92L6c3Hyg8XMTFcw6O3wlnwFl0MTLgIAAAAAgLL4FCiGhISoY8eOSk9Pd+9zOBxKT09X165dvbqG3W7Xjh07FBcXJ0lq3ry5YmNjPa6Zk5OjTZs2eX1NwBRsNumpp0o/5vHHXYlgORI9m0264w5XM2RFuhYJFwEAAAAAQGl8XvI8duxYLV68WK+++qp27typESNGKDc3V4MGDZIkDRgwQJMmTXIf/9hjj+mjjz7STz/9pG3btumee+7Rvn37NGTIEEmuCdBjxozRrFmz9MEHH2jHjh0aMGCAmjRpoj59+lTOpwT8xfjxZU9//vvfy7UEuqCKdi1KRcPFl18mYAQAAAAAAFKwryf07dtXR44c0bRp03Tw4EF16NBBq1evdg9VyczMVFDQxZzy119/1dChQ3Xw4EHVrVtXHTt21IYNG9SmTRv3MRMmTFBubq6GDRumEydO6A9/+INWr16tsLCwSviIgJ+ZNUuqU8cVLpZmwgQpO9t1fDnldy3ecYc0Z44rWPz0U9+v88Ybri3f3XdLTz7puj4AAAAAAAgsFqfT6TS6iIrKyclRTEyMsrOzeZ4izCMrS5o0SXr99dKP69/f9fzFSkrvtmyRZs6UPvxQqug//XffLf3hD1L9+lK3bgSMAAAAAACYlS/5GoEiYLQpU1zPTizLU0+V3dXog6wsaeNG6YMPXKusK+PfBASMAAAAAACYE4EiYDZz53oXFlZyt2K+qggXpYsBo0TICAAAAACAPyNQBMzI2yXQUqV3KxYuoyrCxXzXXSdde62UmEjACAAAAACAvyBQBMzM2yXQDzwgPfdclZaSHy4eOya9+qr05ZeVf4+CXYwSnYwAAAAAABiBQBEwO2+XQN98s2u6SjWpzIEupYlu5NRfn3Lo+psu3qR2sEVNI4IUHWKpuhsDAAAAABCgCBSBmsDbJdC33OLqVKzGlr6CnYtffFG5S6M73WLXrZMdsgQV/36zSKlZpEVhwa7XBI0AAAAAAFQcgSJQk3jbrViFz1UsS2UFjNGNnJq46ryCSggTS9O6jhQfWTRUJHAEAAAAAKBsBIpATZOVJT34oPT++6UfV0VToH1VMGCUXCGjN7NmWnRyaOgr9iqpKTFaigmRIoIvdjfmI3QEAAAAAAQ6AkWgpvrTn6SVK8s+btgwaepUw4PFgrKyXM9e/OEHad8+VzZa+N8+0Y2cmrjyvIKsxtRYUpejJJ0571Tueal+WJASYwgfAQAAANQ8OXlO/Zzr0G/nne6/AxXXlOENI8+vynvX5IYUAkWgJnvwQen557071g+DxXyFuxglVyfjrlyH+ky2l2vZc3UqLXwsSU3+Hx4AAAC4FAxkCiKcMef5gVR7Vq5T3/3qe42B6sZLrGpf38//4uojAkWgpvP2uYr5/DhYLCwrS/rfj05FNHUoPMb1r6ea9j9s5QkjA/X/IQOA6lJSAOANM/1lsSadT+3mPL+m117T/rsVQMkskka0Da5Rfw8jUAQCgbdToAsycHBLReXkOZWRbdfxM06FX/iPOP6DzVNJQaXZ/sOdgNQ3/tgFYbbfuco8n9rNef6eHKd25/h+TwAAENj6JVrVLKrmdCkSKAKBxNduRT8Z3FJZSusoIXA0t9Z1pIZhMm1AUdHz6YIAAAAA/BcdigSKgPllZUmPPy4tXOj9OX/9q+ucGi4/cPz1jEOnz8vd3ZiPQAYAAAAA4CueoUigCNQcvgaLXbpI775bY7oVy8ub52adOe/UvlPSvlPVWBgAAAAAGCB/tVBxTRneOnPeadj5VXnvmvyIJgJFIND5GiyaaGiL0crz0H66IAEAAAJP4edbGxmuVPR8M9de0fMDrfaaHJahbASKAFx8HdxCsFhlKjI9VCr5PwYIKwGgcsXVlpLr+/aXKLP9ZbGmnE/t5jw/EGonkAFgVgSKADz5OriFYNFUygorzfQf7gSk5edPXRBm+p2r7POp3ZznnznvlN1p0aUxQWoSUbOehQQAAOAtAkUARWVlSXfcIX35pffn3H231Lu31K0b4SKqTcGA1MwBRUXPpwsCAAAAQHUiUARQsilTyjfdma5FAAAAAABqLF/yNdZ0AIFm1ixp/37p/vt9O++VV6T4eGn4cFe3IwAAAAAACEgEikAgstmkl18mWAQAAAAAAD4jUAQCWWUEi/37S2+/TbgIAAAAAECAIFAEUDRYtPgw3OGNN6S+felaBAAAAAAgQBAoArgoP1jMzHR1Hd5zj2/n07UIAAAAAECNx5RnAKXLypImTZJef7185999t9S7t9StGxOiAQAAAADwU0x5BlB5bDbp//5Pevpp35ZC5yu4JJrORQAAAAAATI9AEYB3xo3zXApd0XCR5y0CAAAAAGBKLHkGUD5ZWdLGjdIHH5R/ObTEkmgAAAAAAPyAL/kagSKAisvKkh5/XFq0SKrIv1Luvlv6wx+k+vUJGAEAAAAAqEYEigCMUbBr8e9/L3+4GFFfim0tpd0v3XCN1KKuVLd25dYKAAAAAADcCBQBGK+8S6Ivu17q8YBkKfSI185x0qX1pIgQAkYAAAAAACoZgSIA/+LtkuiI+tK9y4qGicXpHCe1iyVcBAAAAACgEhAoAvBPZS2JbpIs9Z7j+3XpXgQAAAAAoEIIFAH4v+LCxYj60j3LpCAvOhRLkx8wSoSMAAAAAAB4gUARgLnkh4vHjknHI6SsupIslXuP9o2kJtFSciMpoW7lXhsAAAAAAJMjUARgbr/+Jv30q/TNIWnLL5V//WYxUlfbxdd0MQIAAAAAApwv+VpwNdUEAN6rW1vqWFvq2ETqc1nlh4v7sl1bYSyVBgAAAACgTHQoAjCP/M7F3Dzpx1+rpnuxsPyQ8fQ56ZyDJdMAAAAAgBqJJc8AAoMRAaPEkmkAAAAAQI1DoAggMBUMGKXqDRklzyXT+QgbAQAAAAAmQKAIAPnyQ8avfpG+PmRcHe0bSXXDpagQKaIWQSMAAAAAwK8wlAUA8hUc8FK4g1Gqvi7Grw8Xv7+4rsZ8hI4AAAAAAD9EhyIAGL1Uuiyd46S4KCkn72KHYz5CRwAAAABAJWDJMwBUVOGQcedRY5dMl6W0TkeJ4BEAAAAAUCqWPANAReUvlc53VYKxS6bLsuWAaytLWcGjRPgIAAAAACgVHYoAUFHFBY2S/4SN5ZUfPp4+V/xy63wEkAAAAABgeix5BgB/kR82HsmVTl4I5Q6cMnfQWJKSuh8JJAEAAADA77HkGQD8ReGl0/n6XFZ8V2M+M3Y3ervsuiTFBZJlhZH5CCUBAAAAoNrQoQgA/qrgUurT5y52OIZfCNbMGDpWtcKhpLeBZHEiQqT6taWzdqlRBGElAAAAgBqNJc8AEChKen5jPkLHyuPNQJvCfOmwJLwEAAAAYCACRQDARWWFjgURQPqHznFSXFT5uysl37szWTYOAAAABDQCRQBA+RUOIItbbp2PALLm8Xa6d2kqcm5x59PBCQAAAFQ5AkUAQPUpqwOSQBKVrazl55UdaHorP/g8elqyWOj4BAAAgKkQKAIAzKO0QLK0MDIfoST8ma/P3jQqDC18bqMIAlEAAIAAQ6AIAAgsJYWS3gSSxSGkBFx8CUSNDEMLnt84QmoWwxJ5AAAAHxEoAgBQUb4MsymJtx2WX/0imf5/jQE/5U0o6i9haMHzWUIPAACqGYEiAABm8utv0pHTUkiQdOw3V4hZ3u7KfL6cT0cmYA7FhaP+FoYShAIAYFoEigAAwDe+TPcuS2WGoQdO0cEJmF1pXaJMlAcAwG/4kq8FV1NNAADAn9WtLXX0078897msaAdnaaqzuzMfXZ5AybYccG1mU5UT5asiDKUbFABQjehQBAAAqAz5XZ6Sq8vJm/CzMCPC0MLnHv9N+vqQ7/cGYDxvBykZvVS+YAD662/S4Vy6QgHAD9ChCAAAUN0Kd3km1DWulooqz1AiI8PQ/PN3HZN+OMYSeQQus3WDJsRI+7Iv/jPrj0OU6P4EgGLRoQgAAICao7ghR2XxhzC04PlMfwf8T+c4KS7Kv4Yg5SP0BFBJGMoCAAAAmFl+MNow3PW6pI5RfwpDGaIEGMufn/spEXwCJlDlgeKLL76op59+WgcPHlT79u31/PPP68orryzzvLfeekv9+vVT79699c9//tO9f+DAgXr11Vc9jk1NTdXq1au9qodAEQAAAPAD3gah+ZgoDwQeb5/1WVBVdHfyLE+giCp9huKKFSs0duxYLVy4UF26dNGCBQuUmpqqXbt2qVGjRiWet3fvXo0bN05//OMfi32/Z8+eWrZsmft1aGior6UBAAAAMFLd2p5/GffX6fHFqc6J8pUdhjJlHmbib8/6LOtZnkYPMZLo7oRf8rlDsUuXLurcubNeeOEFSZLD4VB8fLweeOABPfLII8WeY7fbddVVV2nw4MH6/PPPdeLEiSIdioX3lebs2bM6e/as+3VOTo7i4+PpUAQAAAAQeHwdpGTUUvkffyX8BCrC1+7Oqu7sRI1TZR2KeXl52rp1qyZNmuTeFxQUpJSUFG3cuLHE8x577DE1atRIaWlp+vzzz4s9Zv369WrUqJHq1q2ra6+9VrNmzVL9+vWLPXbOnDmaMWOGL6UDAAAAQM1UeMq8v7oqwdUJWjD8jAiR6tf2zyFKBKDwN/7U3elPU9kJOQ3hU6B49OhR2e12NW7c2GN/48aN9f333xd7zn/+8x8tWbJE27dvL/G6PXv21K233qrmzZvrxx9/1F//+lfdeOON2rhxo6xWa5HjJ02apLFjx7pf53coAgAAAAD8WEnhZ0Ld6q+lLIUDUH8agpR/PqEnjOJP4Wa+giFnVYaZBJiSyvEMRV+cPHlS9957rxYvXqwGDRqUeNxdd93l/nNycrLatWunSy+9VOvXr9d1111X5PjQ0FCesQgAAAAAqFr+3v1ZXNdnSYx67iehJ6pLdYec/ZOl7pdU3/38jE+BYoMGDWS1WnXo0CGP/YcOHVJsbGyR43/88Uft3btXvXr1cu9zOByuGwcHa9euXbr00kuLnNeiRQs1aNBAGRkZxQaKAAAAAABANSv0LElld3cScqIyvLFDatMwYDsVfQoUQ0JC1LFjR6Wnp6tPnz6SXAFhenq6Ro0aVeT4yy67TDt27PDYN2XKFJ08eVLPPvtsicuUs7KydOzYMcXFxflSHgAAAAAA8Df+FnoWDjlLe5ankUvdCT79m1PSkdMEit4aO3as7rvvPnXq1ElXXnmlFixYoNzcXA0aNEiSNGDAADVt2lRz5sxRWFiYLr/8co/z69SpI0nu/adOndKMGTN02223KTY2Vj/++KMmTJigxMREpaamVvDjAQAAAAAAFFJcyOlvz/KsaHcnnZ1VyyKpYbjRVRjG50Cxb9++OnLkiKZNm6aDBw+qQ4cOWr16tXtQS2ZmpoKCgry+ntVq1TfffKNXX31VJ06cUJMmTXTDDTdo5syZPCcRAAAAAAAELn/q7vQ14KyO7k6jQk6LpLuTA7Y7UZIsTqfTaXQRFZWTk6OYmBhlZ2crOjra6HIAAAAAAABQHX79rWjIWZVhZg2e8uxLvlalU54BAAAAAACAKuNPXZwBxPu1yQAAAAAAAAACHoEiAAAAAAAAAK8RKAIAAAAAAADwGoEiAAAAAAAAAK8RKAIAAAAAAADwGoEiAAAAAAAAAK8RKAIAAAAAAADwGoEiAAAAAAAAAK8RKAIAAAAAAADwGoEiAAAAAAAAAK8RKAIAAAAAAADwGoEiAAAAAAAAAK8RKAIAAAAAAADwGoEiAAAAAAAAAK8RKAIAAAAAAADwGoEiAAAAAAAAAK8RKAIAAAAAAADwGoEiAAAAAAAAAK8RKAIAAAAAAADwGoEiAAAAAAAAAK8RKAIAAAAAAADwGoEiAAAAAAAAAK8FG11AZXA6nZKknJwcgysBAAAAAAAAzCc/V8vP2UpTIwLFkydPSpLi4+MNrgQAAAAAAAAwr5MnTyomJqbUYyxOb2JHP+dwOPTLL78oKipKFovF6HKqRE5OjuLj47V//35FR0cbXQ5Qpfh9RyDh9x2BhN93BBJ+3xFI+H1HIKnJv+9Op1MnT55UkyZNFBRU+lMSa0SHYlBQkGw2m9FlVIvo6Oga9wsLlITfdwQSft8RSPh9RyDh9x2BhN93BJKa+vteVmdiPoayAAAAAAAAAPAagSIAAAAAAAAArxEomkRoaKgeffRRhYaGGl0KUOX4fUcg4fcdgYTfdwQSft8RSPh9RyDh992lRgxlAQAAAAAAAFA96FAEAAAAAAD4/+3df0zU9R8H8OfBcQdoeAhxJxqKzUkFOZJkF1Z/yCDHMtPVYqexanPlOUGbYTWsrRmIqz80wx9/ZFsa5aapTNsuIBgTAQ9QETvZJGnqyUzPI5E47l7fv/h8/STqMZGD8/nYbuPe79c+e7+3J7fP57XP3YeI/MaGIhEREREREREREfmNDUUiIiIiIiIiIiLyGxuKRERERERERERE5Dc2FImIiIiIiIiIiMhvbCiOA9u2bcOMGTMQHh6O9PR0NDY2BnpJRMNWXFyM559/Ho899hji4uKwePFiOBwOVU1fXx+sVitiYmIwceJELF26FFeuXFHVdHV1IScnB5GRkYiLi8O6deswMDAwmlshGpaSkhJoNBoUFBQoY8w6BZuLFy9i2bJliImJQUREBFJSUnDixAllXkSwYcMGTJkyBREREcjMzERHR4fqGNeuXYPFYkFUVBQMBgPee+89/PPPP6O9FaJ78nq9KCoqQmJiIiIiIvDkk0/iiy++gIgoNcw7jVe1tbV49dVXER8fD41Gg19++UU1P1LZPnXqFF588UWEh4fjiSeeQGlp6cPeGtEd7pV3j8eDwsJCpKSkYMKECYiPj8fbb7+NS5cuqY7xqOedDcUx7qeffsLatWvx2Wefobm5GXPmzEF2dja6u7sDvTSiYampqYHVasXx48dhs9ng8XiQlZWFmzdvKjVr1qzB4cOHsW/fPtTU1ODSpUtYsmSJMu/1epGTk4P+/n4cO3YM33//PXbv3o0NGzYEYktE99XU1IQdO3bg2WefVY0z6xRMrl+/joyMDISFheHo0aNob2/HV199hejoaKWmtLQUW7Zswfbt29HQ0IAJEyYgOzsbfX19So3FYsGZM2dgs9lQUVGB2tparFixIhBbIrqrTZs2oaysDN988w3Onj2LTZs2obS0FFu3blVqmHcar27evIk5c+Zg27ZtQ86PRLbdbjeysrIwffp02O12bN68GZ9//jl27tz50PdHdLt75b23txfNzc0oKipCc3Mz9u/fD4fDgUWLFqnqHvm8C41p8+bNE6vVqrz3er0SHx8vxcXFAVwV0YPr7u4WAFJTUyMiIi6XS8LCwmTfvn1KzdmzZwWA1NfXi4jIkSNHJCQkRJxOp1JTVlYmUVFR8u+//47uBojuo6enR2bNmiU2m01efvllyc/PFxFmnYJPYWGhzJ8//67zPp9PTCaTbN68WRlzuVyi1+vlxx9/FBGR9vZ2ASBNTU1KzdGjR0Wj0cjFixcf3uKJhiknJ0feffdd1diSJUvEYrGICPNOwQOAHDhwQHk/Utn+9ttvJTo6WnU+U1hYKLNnz37IOyK6u//mfSiNjY0CQC5cuCAizLuICO9QHMP6+/tht9uRmZmpjIWEhCAzMxP19fUBXBnRg7tx4wYAYPLkyQAAu90Oj8ejyntSUhISEhKUvNfX1yMlJQVGo1Gpyc7OhtvtxpkzZ0Zx9UT3Z7VakZOTo8o0wKxT8Dl06BDS0tLwxhtvIC4uDqmpqdi1a5cy39nZCafTqcr8pEmTkJ6ersq8wWBAWlqaUpOZmYmQkBA0NDSM3maI7uOFF15AZWUlzp07BwA4efIk6urqsHDhQgDMOwWvkcp2fX09XnrpJeh0OqUmOzsbDocD169fH6XdEA3fjRs3oNFoYDAYADDvAKAN9ALo7q5evQqv16u6oAQAo9GIP/74I0CrInpwPp8PBQUFyMjIQHJyMgDA6XRCp9MpH9CDjEYjnE6nUjPU/8PgHNFYUV5ejubmZjQ1Nd0xx6xTsDl//jzKysqwdu1afPLJJ2hqasLq1auh0+mQl5enZHaoTN+e+bi4ONW8VqvF5MmTmXkaU9avXw+3242kpCSEhobC6/Vi48aNsFgsAMC8U9AaqWw7nU4kJibecYzBudt/LoNorOjr60NhYSFyc3MRFRUFgHkH2FAkogCwWq1oa2tDXV1doJdCNOL++usv5Ofnw2azITw8PNDLIXrofD4f0tLS8OWXXwIAUlNT0dbWhu3btyMvLy/AqyMaWT///DP27NmDvXv34plnnkFraysKCgoQHx/PvBMRBSGPx4M333wTIoKysrJAL2dM4Veex7DY2FiEhobe8eTPK1euwGQyBWhVRA9m1apVqKioQHV1NaZNm6aMm0wm9Pf3w+Vyqepvz7vJZBry/2FwjmgssNvt6O7uxnPPPQetVgutVouamhps2bIFWq0WRqORWaegMmXKFDz99NOqsaeeegpdXV0A/p/Ze53PmEymOx44NzAwgGvXrjHzNKasW7cO69evx1tvvYWUlBQsX74ca9asQXFxMQDmnYLXSGWb5zg0ngw2Ey9cuACbzabcnQgw7wAbimOaTqfD3LlzUVlZqYz5fD5UVlbCbDYHcGVEwyciWLVqFQ4cOICqqqo7bv2eO3cuwsLCVHl3OBzo6upS8m42m3H69GnVB/fgB/t/L2aJAmXBggU4ffo0WltblVdaWhosFovyN7NOwSQjIwMOh0M1du7cOUyfPh0AkJiYCJPJpMq82+1GQ0ODKvMulwt2u12pqaqqgs/nQ3p6+ijsgsg/vb29CAlRX0KFhobC5/MBYN4peI1Uts1mM2pra+HxeJQam82G2bNnj/uvf1JwGWwmdnR04LfffkNMTIxqnnkHn/I81pWXl4ter5fdu3dLe3u7rFixQgwGg+rJn0TjwQcffCCTJk2S33//XS5fvqy8ent7lZr3339fEhISpKqqSk6cOCFms1nMZrMyPzAwIMnJyZKVlSWtra3y66+/yuOPPy4ff/xxILZE5Lfbn/IswqxTcGlsbBStVisbN26Ujo4O2bNnj0RGRsoPP/yg1JSUlIjBYJCDBw/KqVOn5LXXXpPExES5deuWUvPKK69IamqqNDQ0SF1dncyaNUtyc3MDsSWiu8rLy5OpU6dKRUWFdHZ2yv79+yU2NlY++ugjpYZ5p/Gqp6dHWlpapKWlRQDI119/LS0tLcpTbUci2y6XS4xGoyxfvlza2tqkvLxcIiMjZceOHaO+X3q03Svv/f39smjRIpk2bZq0traqrl9vf2Lzo553NhTHga1bt0pCQoLodDqZN2+eHD9+PNBLIho2AEO+vvvuO6Xm1q1bsnLlSomOjpbIyEh5/fXX5fLly6rj/Pnnn7Jw4UKJiIiQ2NhY+fDDD8Xj8YzyboiG578NRWadgs3hw4clOTlZ9Hq9JCUlyc6dO1XzPp9PioqKxGg0il6vlwULFojD4VDV/P3335KbmysTJ06UqKgoeeedd6Snp2c0t0F0X263W/Lz8yUhIUHCw8Nl5syZ8umnn6ouMJl3Gq+qq6uHPF/Py8sTkZHL9smTJ2X+/Pmi1+tl6tSpUlJSMlpbJFLcK++dnZ13vX6trq5WjvGo510jIjJ690MSERERERERERHReMbfUCQiIiIiIiIiIiK/saFIREREREREREREfmNDkYiIiIiIiIiIiPzGhiIRERERERERERH5jQ1FIiIiIiIiIiIi8hsbikREREREREREROQ3NhSJiIiIiIiIiIjIb2woEhERERERERERkd/YUCQiIiIiIiIiIiK/saFIREREREREREREfmNDkYiIiIiIiIiIiPz2P+t94g/96+ypAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2\n",
        "# For this exercise do the following in the cells below\n",
        "\n",
        "# Build a model with two hidden layers, each with 6 nodes\n",
        "# Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "# use a learning rate of .003 and train for 1500 epochs\n",
        "# graph the trajectory of the loss functions accracy on both train and test set\n",
        "# Plot the roc curve for the predictions\n",
        "\n",
        "# Begin Solution\n",
        "model_2 = Sequential()\n",
        "model_2.add(Dense(6,input_shape=(8,),activation='relu'))\n",
        "model_2.add(Dense(6, activation='relu'))\n",
        "model_2.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_2.compile(SGD(lr = .003),\"binary_crossentropy\",metrics=['accuracy'])\n",
        "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT-emLLwxstY",
        "outputId": "4a627431-23b7-48b4-951a-5aacfee30786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 2s 48ms/step - loss: 0.6975 - accuracy: 0.4236 - val_loss: 0.6917 - val_accuracy: 0.4948\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.6920 - accuracy: 0.5417 - val_loss: 0.6869 - val_accuracy: 0.5417\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.6871 - accuracy: 0.6181 - val_loss: 0.6826 - val_accuracy: 0.6302\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6826 - accuracy: 0.6458 - val_loss: 0.6787 - val_accuracy: 0.6510\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.6785 - accuracy: 0.6580 - val_loss: 0.6751 - val_accuracy: 0.6562\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6748 - accuracy: 0.6667 - val_loss: 0.6719 - val_accuracy: 0.6771\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.6715 - accuracy: 0.6701 - val_loss: 0.6689 - val_accuracy: 0.6667\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.6684 - accuracy: 0.6701 - val_loss: 0.6662 - val_accuracy: 0.6667\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.6655 - accuracy: 0.6649 - val_loss: 0.6637 - val_accuracy: 0.6719\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.6629 - accuracy: 0.6649 - val_loss: 0.6615 - val_accuracy: 0.6615\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6605 - accuracy: 0.6632 - val_loss: 0.6594 - val_accuracy: 0.6615\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.6583 - accuracy: 0.6649 - val_loss: 0.6575 - val_accuracy: 0.6615\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.6563 - accuracy: 0.6667 - val_loss: 0.6557 - val_accuracy: 0.6667\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.6544 - accuracy: 0.6649 - val_loss: 0.6541 - val_accuracy: 0.6667\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.6526 - accuracy: 0.6667 - val_loss: 0.6525 - val_accuracy: 0.6667\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.6509 - accuracy: 0.6649 - val_loss: 0.6511 - val_accuracy: 0.6667\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6494 - accuracy: 0.6649 - val_loss: 0.6497 - val_accuracy: 0.6667\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.6479 - accuracy: 0.6649 - val_loss: 0.6485 - val_accuracy: 0.6667\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.6465 - accuracy: 0.6632 - val_loss: 0.6473 - val_accuracy: 0.6667\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6452 - accuracy: 0.6615 - val_loss: 0.6461 - val_accuracy: 0.6667\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6439 - accuracy: 0.6615 - val_loss: 0.6449 - val_accuracy: 0.6667\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.6426 - accuracy: 0.6632 - val_loss: 0.6437 - val_accuracy: 0.6667\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.6414 - accuracy: 0.6632 - val_loss: 0.6425 - val_accuracy: 0.6667\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6402 - accuracy: 0.6632 - val_loss: 0.6413 - val_accuracy: 0.6667\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6390 - accuracy: 0.6649 - val_loss: 0.6402 - val_accuracy: 0.6667\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6379 - accuracy: 0.6649 - val_loss: 0.6391 - val_accuracy: 0.6667\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6369 - accuracy: 0.6649 - val_loss: 0.6380 - val_accuracy: 0.6667\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6358 - accuracy: 0.6667 - val_loss: 0.6368 - val_accuracy: 0.6719\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.6347 - accuracy: 0.6701 - val_loss: 0.6356 - val_accuracy: 0.6719\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.6336 - accuracy: 0.6701 - val_loss: 0.6345 - val_accuracy: 0.6719\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6325 - accuracy: 0.6719 - val_loss: 0.6333 - val_accuracy: 0.6719\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.6314 - accuracy: 0.6736 - val_loss: 0.6320 - val_accuracy: 0.6719\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.6302 - accuracy: 0.6753 - val_loss: 0.6306 - val_accuracy: 0.6719\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.6290 - accuracy: 0.6736 - val_loss: 0.6292 - val_accuracy: 0.6719\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6276 - accuracy: 0.6753 - val_loss: 0.6277 - val_accuracy: 0.6771\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.6264 - accuracy: 0.6771 - val_loss: 0.6263 - val_accuracy: 0.6823\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6251 - accuracy: 0.6771 - val_loss: 0.6249 - val_accuracy: 0.6771\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.6238 - accuracy: 0.6788 - val_loss: 0.6234 - val_accuracy: 0.6771\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.6224 - accuracy: 0.6806 - val_loss: 0.6218 - val_accuracy: 0.6875\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6210 - accuracy: 0.6823 - val_loss: 0.6201 - val_accuracy: 0.6927\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.6196 - accuracy: 0.6823 - val_loss: 0.6184 - val_accuracy: 0.6927\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.6182 - accuracy: 0.6875 - val_loss: 0.6166 - val_accuracy: 0.6979\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.6168 - accuracy: 0.6875 - val_loss: 0.6148 - val_accuracy: 0.6979\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6153 - accuracy: 0.6910 - val_loss: 0.6130 - val_accuracy: 0.6979\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.6139 - accuracy: 0.6910 - val_loss: 0.6112 - val_accuracy: 0.6979\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.6124 - accuracy: 0.6927 - val_loss: 0.6092 - val_accuracy: 0.6979\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.6108 - accuracy: 0.6910 - val_loss: 0.6074 - val_accuracy: 0.6979\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.6093 - accuracy: 0.6962 - val_loss: 0.6055 - val_accuracy: 0.6979\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.6077 - accuracy: 0.6997 - val_loss: 0.6037 - val_accuracy: 0.7083\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.6059 - accuracy: 0.7014 - val_loss: 0.6018 - val_accuracy: 0.7031\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6041 - accuracy: 0.7049 - val_loss: 0.6000 - val_accuracy: 0.7031\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6024 - accuracy: 0.7066 - val_loss: 0.5982 - val_accuracy: 0.6979\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6006 - accuracy: 0.7118 - val_loss: 0.5962 - val_accuracy: 0.6979\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5988 - accuracy: 0.7101 - val_loss: 0.5943 - val_accuracy: 0.7031\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.7083 - val_loss: 0.5923 - val_accuracy: 0.6979\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5953 - accuracy: 0.7135 - val_loss: 0.5905 - val_accuracy: 0.6927\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5936 - accuracy: 0.7101 - val_loss: 0.5887 - val_accuracy: 0.6979\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5921 - accuracy: 0.7083 - val_loss: 0.5869 - val_accuracy: 0.7031\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.7135 - val_loss: 0.5852 - val_accuracy: 0.7031\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5889 - accuracy: 0.7153 - val_loss: 0.5835 - val_accuracy: 0.7031\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5875 - accuracy: 0.7153 - val_loss: 0.5819 - val_accuracy: 0.7031\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.7188 - val_loss: 0.5803 - val_accuracy: 0.7135\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5846 - accuracy: 0.7240 - val_loss: 0.5787 - val_accuracy: 0.7135\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5830 - accuracy: 0.7240 - val_loss: 0.5771 - val_accuracy: 0.7135\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5816 - accuracy: 0.7222 - val_loss: 0.5757 - val_accuracy: 0.7135\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.7222 - val_loss: 0.5742 - val_accuracy: 0.7135\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5789 - accuracy: 0.7222 - val_loss: 0.5727 - val_accuracy: 0.7188\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.7222 - val_loss: 0.5713 - val_accuracy: 0.7188\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5762 - accuracy: 0.7222 - val_loss: 0.5699 - val_accuracy: 0.7188\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5750 - accuracy: 0.7222 - val_loss: 0.5686 - val_accuracy: 0.7240\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5737 - accuracy: 0.7222 - val_loss: 0.5673 - val_accuracy: 0.7240\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5725 - accuracy: 0.7222 - val_loss: 0.5660 - val_accuracy: 0.7240\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5712 - accuracy: 0.7257 - val_loss: 0.5647 - val_accuracy: 0.7292\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.7274 - val_loss: 0.5635 - val_accuracy: 0.7344\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5689 - accuracy: 0.7292 - val_loss: 0.5623 - val_accuracy: 0.7344\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5678 - accuracy: 0.7292 - val_loss: 0.5612 - val_accuracy: 0.7344\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.7292 - val_loss: 0.5601 - val_accuracy: 0.7396\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5655 - accuracy: 0.7309 - val_loss: 0.5590 - val_accuracy: 0.7448\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5644 - accuracy: 0.7344 - val_loss: 0.5579 - val_accuracy: 0.7500\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.7326 - val_loss: 0.5569 - val_accuracy: 0.7500\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5624 - accuracy: 0.7326 - val_loss: 0.5559 - val_accuracy: 0.7448\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.7326 - val_loss: 0.5550 - val_accuracy: 0.7448\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5604 - accuracy: 0.7344 - val_loss: 0.5540 - val_accuracy: 0.7448\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.7344 - val_loss: 0.5530 - val_accuracy: 0.7448\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5586 - accuracy: 0.7378 - val_loss: 0.5520 - val_accuracy: 0.7448\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5576 - accuracy: 0.7361 - val_loss: 0.5510 - val_accuracy: 0.7500\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5567 - accuracy: 0.7361 - val_loss: 0.5500 - val_accuracy: 0.7500\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.7344 - val_loss: 0.5490 - val_accuracy: 0.7500\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.7344 - val_loss: 0.5480 - val_accuracy: 0.7500\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5541 - accuracy: 0.7344 - val_loss: 0.5471 - val_accuracy: 0.7500\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.7344 - val_loss: 0.5462 - val_accuracy: 0.7500\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5525 - accuracy: 0.7326 - val_loss: 0.5454 - val_accuracy: 0.7500\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.7361 - val_loss: 0.5446 - val_accuracy: 0.7500\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.7361 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.7361 - val_loss: 0.5430 - val_accuracy: 0.7500\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5496 - accuracy: 0.7361 - val_loss: 0.5422 - val_accuracy: 0.7500\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5489 - accuracy: 0.7361 - val_loss: 0.5414 - val_accuracy: 0.7552\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.7378 - val_loss: 0.5407 - val_accuracy: 0.7552\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.7378 - val_loss: 0.5400 - val_accuracy: 0.7552\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.7378 - val_loss: 0.5392 - val_accuracy: 0.7552\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.7378 - val_loss: 0.5385 - val_accuracy: 0.7552\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.7378 - val_loss: 0.5379 - val_accuracy: 0.7604\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7378 - val_loss: 0.5372 - val_accuracy: 0.7604\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7378 - val_loss: 0.5365 - val_accuracy: 0.7604\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7396 - val_loss: 0.5357 - val_accuracy: 0.7604\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5427 - accuracy: 0.7413 - val_loss: 0.5350 - val_accuracy: 0.7656\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5418 - accuracy: 0.7413 - val_loss: 0.5343 - val_accuracy: 0.7656\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.7413 - val_loss: 0.5337 - val_accuracy: 0.7656\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.7413 - val_loss: 0.5330 - val_accuracy: 0.7656\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7413 - val_loss: 0.5324 - val_accuracy: 0.7604\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5390 - accuracy: 0.7431 - val_loss: 0.5318 - val_accuracy: 0.7604\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5383 - accuracy: 0.7431 - val_loss: 0.5311 - val_accuracy: 0.7604\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7448 - val_loss: 0.5305 - val_accuracy: 0.7604\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.7465 - val_loss: 0.5300 - val_accuracy: 0.7604\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7465 - val_loss: 0.5294 - val_accuracy: 0.7604\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.7465 - val_loss: 0.5289 - val_accuracy: 0.7604\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7465 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7465 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7483 - val_loss: 0.5271 - val_accuracy: 0.7656\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7465 - val_loss: 0.5266 - val_accuracy: 0.7708\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5317 - accuracy: 0.7465 - val_loss: 0.5260 - val_accuracy: 0.7708\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7483 - val_loss: 0.5255 - val_accuracy: 0.7708\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7483 - val_loss: 0.5249 - val_accuracy: 0.7708\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7483 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7517 - val_loss: 0.5239 - val_accuracy: 0.7656\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7535 - val_loss: 0.5234 - val_accuracy: 0.7656\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7535 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7552 - val_loss: 0.5222 - val_accuracy: 0.7708\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7552 - val_loss: 0.5216 - val_accuracy: 0.7708\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5247 - accuracy: 0.7552 - val_loss: 0.5211 - val_accuracy: 0.7708\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7552 - val_loss: 0.5205 - val_accuracy: 0.7708\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7569 - val_loss: 0.5200 - val_accuracy: 0.7708\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.7708\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7604 - val_loss: 0.5190 - val_accuracy: 0.7708\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.7604 - val_loss: 0.5185 - val_accuracy: 0.7656\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5202 - accuracy: 0.7604 - val_loss: 0.5181 - val_accuracy: 0.7656\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5195 - accuracy: 0.7587 - val_loss: 0.5176 - val_accuracy: 0.7656\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5187 - accuracy: 0.7622 - val_loss: 0.5172 - val_accuracy: 0.7708\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7639 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7622 - val_loss: 0.5164 - val_accuracy: 0.7708\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7639 - val_loss: 0.5160 - val_accuracy: 0.7760\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5160 - accuracy: 0.7639 - val_loss: 0.5156 - val_accuracy: 0.7760\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7656 - val_loss: 0.5152 - val_accuracy: 0.7760\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7656 - val_loss: 0.5148 - val_accuracy: 0.7760\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7656 - val_loss: 0.5144 - val_accuracy: 0.7760\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.7656 - val_loss: 0.5140 - val_accuracy: 0.7708\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7639 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7674 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.7674 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7656 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7674 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7691 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7656 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7674 - val_loss: 0.5115 - val_accuracy: 0.7656\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7674 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7691 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7674 - val_loss: 0.5107 - val_accuracy: 0.7604\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7691 - val_loss: 0.5105 - val_accuracy: 0.7604\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7691 - val_loss: 0.5102 - val_accuracy: 0.7604\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7708 - val_loss: 0.5099 - val_accuracy: 0.7604\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7726 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7743 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7743 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4997 - accuracy: 0.7743 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.7743 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7743 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7760 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.7760 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7760 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.7778 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.7795 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7778 - val_loss: 0.5069 - val_accuracy: 0.7604\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7760 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.7795 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4921 - accuracy: 0.7743 - val_loss: 0.5061 - val_accuracy: 0.7604\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.7778 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4906 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4898 - accuracy: 0.7743 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4889 - accuracy: 0.7726 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4881 - accuracy: 0.7726 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7743 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4866 - accuracy: 0.7726 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4858 - accuracy: 0.7743 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7743 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4840 - accuracy: 0.7760 - val_loss: 0.5030 - val_accuracy: 0.7604\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4830 - accuracy: 0.7760 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4822 - accuracy: 0.7760 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4813 - accuracy: 0.7778 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4805 - accuracy: 0.7778 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4798 - accuracy: 0.7795 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4791 - accuracy: 0.7795 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4783 - accuracy: 0.7812 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4776 - accuracy: 0.7795 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4769 - accuracy: 0.7795 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4763 - accuracy: 0.7795 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4755 - accuracy: 0.7812 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4749 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.7795 - val_loss: 0.4992 - val_accuracy: 0.7656\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4735 - accuracy: 0.7812 - val_loss: 0.4989 - val_accuracy: 0.7656\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4729 - accuracy: 0.7795 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4724 - accuracy: 0.7795 - val_loss: 0.4984 - val_accuracy: 0.7656\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7760 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7760 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7760 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4700 - accuracy: 0.7743 - val_loss: 0.4974 - val_accuracy: 0.7656\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7743 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7726 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7726 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7726 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7708 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7708 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7726 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7708 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7726 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7726 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7726 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7726 - val_loss: 0.4959 - val_accuracy: 0.7604\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.7743 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7743 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7743 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7743 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7726 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7726 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7726 - val_loss: 0.4954 - val_accuracy: 0.7656\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7726 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.7708 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7726 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7708 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7691 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7691 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7691 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7691 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7691 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7691 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7691 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7691 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7674 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.7674 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7674 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7674 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7674 - val_loss: 0.4948 - val_accuracy: 0.7708\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.7674 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7674 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.7674 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7674 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7691 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7656 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7656 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7639 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7674 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7674 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7674 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7674 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7674 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4541 - accuracy: 0.7674 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.7674 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7656 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.7674 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.7674 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7674 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7674 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7674 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7674 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7674 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7674 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7674 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7674 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7674 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7656 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.7674 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7691 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7691 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7674 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7674 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7674 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7674 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7674 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7674 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7691 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7674 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7708 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7674 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7691 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7674 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.7708 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7691 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7691 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7691 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7691 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7708 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7708 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7708 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7708 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7708 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.7708 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7708 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7708 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.7708 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7708 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7726 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7691 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7726 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7726 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.7691 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7726 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7726 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.7726 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7726 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7726 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7726 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7726 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7726 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7726 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7726 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7726 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7726 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7708 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.7726 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.7708 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7708 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7708 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7743 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.7708 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7708 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.7743 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4454 - accuracy: 0.7708 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.7743 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.7760 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4451 - accuracy: 0.7743 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.7726 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.7778 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.7726 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.7760 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.7726 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7760 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4444 - accuracy: 0.7726 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4443 - accuracy: 0.7743 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.7743 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7743 - val_loss: 0.4955 - val_accuracy: 0.7708\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.7743 - val_loss: 0.4955 - val_accuracy: 0.7708\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7743 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.7760 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7743 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4436 - accuracy: 0.7743 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.7743 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.7726 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.7743 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4433 - accuracy: 0.7760 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4431 - accuracy: 0.7726 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.7778 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.7778 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4430 - accuracy: 0.7778 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.7726 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.7743 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.7760 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4427 - accuracy: 0.7743 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.7778 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.7778 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4424 - accuracy: 0.7778 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4423 - accuracy: 0.7778 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7760 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7778 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7778 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7760 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7760 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7778 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7760 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7778 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7760 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7760 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.7760 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7760 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7760 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7760 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.7778 - val_loss: 0.4969 - val_accuracy: 0.7760\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7760 - val_loss: 0.4969 - val_accuracy: 0.7760\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.7760 - val_loss: 0.4970 - val_accuracy: 0.7760\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7760\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7743 - val_loss: 0.4971 - val_accuracy: 0.7760\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.7743 - val_loss: 0.4971 - val_accuracy: 0.7760\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7743 - val_loss: 0.4971 - val_accuracy: 0.7760\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7778 - val_loss: 0.4971 - val_accuracy: 0.7760\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.7726 - val_loss: 0.4971 - val_accuracy: 0.7760\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7726 - val_loss: 0.4972 - val_accuracy: 0.7760\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7743 - val_loss: 0.4972 - val_accuracy: 0.7760\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7743 - val_loss: 0.4972 - val_accuracy: 0.7760\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.7743 - val_loss: 0.4972 - val_accuracy: 0.7760\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.7743 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.7743 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.7726 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7743 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7743 - val_loss: 0.4975 - val_accuracy: 0.7760\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7743 - val_loss: 0.4975 - val_accuracy: 0.7760\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7743 - val_loss: 0.4976 - val_accuracy: 0.7760\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7743 - val_loss: 0.4976 - val_accuracy: 0.7760\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.7743 - val_loss: 0.4977 - val_accuracy: 0.7760\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7760\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7743 - val_loss: 0.4977 - val_accuracy: 0.7760\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7743 - val_loss: 0.4978 - val_accuracy: 0.7760\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7743 - val_loss: 0.4978 - val_accuracy: 0.7760\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7760 - val_loss: 0.4979 - val_accuracy: 0.7760\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.7760 - val_loss: 0.4979 - val_accuracy: 0.7760\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7760 - val_loss: 0.4979 - val_accuracy: 0.7760\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7760\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7778 - val_loss: 0.4981 - val_accuracy: 0.7760\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7778 - val_loss: 0.4981 - val_accuracy: 0.7760\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7760 - val_loss: 0.4981 - val_accuracy: 0.7760\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.7760 - val_loss: 0.4981 - val_accuracy: 0.7760\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7778 - val_loss: 0.4981 - val_accuracy: 0.7760\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7795 - val_loss: 0.4981 - val_accuracy: 0.7760\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7795 - val_loss: 0.4982 - val_accuracy: 0.7760\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7795 - val_loss: 0.4982 - val_accuracy: 0.7760\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7795 - val_loss: 0.4982 - val_accuracy: 0.7760\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7795 - val_loss: 0.4982 - val_accuracy: 0.7760\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7778 - val_loss: 0.4982 - val_accuracy: 0.7760\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7795 - val_loss: 0.4982 - val_accuracy: 0.7760\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.7795 - val_loss: 0.4983 - val_accuracy: 0.7760\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.7795 - val_loss: 0.4983 - val_accuracy: 0.7760\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.7778 - val_loss: 0.4983 - val_accuracy: 0.7760\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7760\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7778 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7760\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7778 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7795 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.7795 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7795 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7795 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.7812 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.7812 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7795 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.7830 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7795 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7812 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7812 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.7812 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4370 - accuracy: 0.7830 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7795 - val_loss: 0.4987 - val_accuracy: 0.7760\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7795 - val_loss: 0.4989 - val_accuracy: 0.7708\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7830 - val_loss: 0.4989 - val_accuracy: 0.7708\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.7812 - val_loss: 0.4990 - val_accuracy: 0.7656\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.7812 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7812 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7830 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7847 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4364 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4363 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7656\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.7830 - val_loss: 0.4993 - val_accuracy: 0.7656\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4363 - accuracy: 0.7830 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4363 - accuracy: 0.7830 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4362 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7656\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4363 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7656\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4362 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4360 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4360 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.7830 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4359 - accuracy: 0.7830 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.7812 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.7830 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4356 - accuracy: 0.7830 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4356 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4355 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4355 - accuracy: 0.7812 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4354 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.7830 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4354 - accuracy: 0.7830 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.7812 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4352 - accuracy: 0.7865 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7865 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7865 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7865 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7865 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.7865 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.7865 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.7865 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7865 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7865 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4344 - accuracy: 0.7865 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7865 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.4994 - val_accuracy: 0.7656\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7847 - val_loss: 0.4994 - val_accuracy: 0.7656\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.4995 - val_accuracy: 0.7604\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7882 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7604\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7604\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7604\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.4995 - val_accuracy: 0.7604\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.7865 - val_loss: 0.4993 - val_accuracy: 0.7604\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.4994 - val_accuracy: 0.7604\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.4993 - val_accuracy: 0.7604\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.4994 - val_accuracy: 0.7604\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.7865 - val_loss: 0.4993 - val_accuracy: 0.7604\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.4993 - val_accuracy: 0.7604\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7604\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.4993 - val_accuracy: 0.7604\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.4993 - val_accuracy: 0.7604\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7865 - val_loss: 0.4992 - val_accuracy: 0.7604\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7865 - val_loss: 0.4992 - val_accuracy: 0.7604\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7604\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.4992 - val_accuracy: 0.7604\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7604\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.4992 - val_accuracy: 0.7604\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7830 - val_loss: 0.4993 - val_accuracy: 0.7604\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.4991 - val_accuracy: 0.7604\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7830 - val_loss: 0.4991 - val_accuracy: 0.7604\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.4991 - val_accuracy: 0.7604\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.4990 - val_accuracy: 0.7604\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.4991 - val_accuracy: 0.7604\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.4990 - val_accuracy: 0.7604\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.4990 - val_accuracy: 0.7604\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.4989 - val_accuracy: 0.7604\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.4989 - val_accuracy: 0.7604\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.4989 - val_accuracy: 0.7604\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.4989 - val_accuracy: 0.7604\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.4989 - val_accuracy: 0.7604\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.4989 - val_accuracy: 0.7604\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.4989 - val_accuracy: 0.7604\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7865 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7830 - val_loss: 0.4989 - val_accuracy: 0.7604\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7865 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.4987 - val_accuracy: 0.7604\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.4986 - val_accuracy: 0.7604\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7882 - val_loss: 0.4987 - val_accuracy: 0.7656\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7865 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7865 - val_loss: 0.4985 - val_accuracy: 0.7656\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.4985 - val_accuracy: 0.7656\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.4985 - val_accuracy: 0.7656\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7882 - val_loss: 0.4985 - val_accuracy: 0.7656\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.4984 - val_accuracy: 0.7656\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4320 - accuracy: 0.7865 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4319 - accuracy: 0.7865 - val_loss: 0.4984 - val_accuracy: 0.7656\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4319 - accuracy: 0.7865 - val_loss: 0.4984 - val_accuracy: 0.7656\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4318 - accuracy: 0.7865 - val_loss: 0.4984 - val_accuracy: 0.7656\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4318 - accuracy: 0.7865 - val_loss: 0.4984 - val_accuracy: 0.7656\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.4984 - val_accuracy: 0.7656\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7656\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.7899 - val_loss: 0.4980 - val_accuracy: 0.7656\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.4980 - val_accuracy: 0.7656\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7656\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7656\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.4980 - val_accuracy: 0.7656\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7656\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.4978 - val_accuracy: 0.7656\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7656\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7656\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.4975 - val_accuracy: 0.7656\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4311 - accuracy: 0.7882 - val_loss: 0.4975 - val_accuracy: 0.7656\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4310 - accuracy: 0.7847 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7847 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7708\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7847 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.7847 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7847 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7865 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7882 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7830 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7830 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7865 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7830 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7830 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7830 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7812 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4302 - accuracy: 0.7812 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.7830 - val_loss: 0.4962 - val_accuracy: 0.7760\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7795 - val_loss: 0.4962 - val_accuracy: 0.7760\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7795 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.7795 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7795 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7830 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7812 - val_loss: 0.4962 - val_accuracy: 0.7760\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.7812 - val_loss: 0.4962 - val_accuracy: 0.7760\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7830 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7830 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7812 - val_loss: 0.4962 - val_accuracy: 0.7604\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7830 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7830 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7830 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4289 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4287 - accuracy: 0.7795 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7795 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7795 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7812 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.7830 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.7795 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.7795 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.7795 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7795 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7830 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7795 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.7847 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7830 - val_loss: 0.4958 - val_accuracy: 0.7760\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7812 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.7778 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.7795 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.7812 - val_loss: 0.4958 - val_accuracy: 0.7760\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.7795 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.7795 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.7830 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4280 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4276 - accuracy: 0.7795 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.7795 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4277 - accuracy: 0.7795 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4275 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4276 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4275 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4274 - accuracy: 0.7812 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.7830 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.7812 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.7830 - val_loss: 0.4962 - val_accuracy: 0.7760\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.7812 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4273 - accuracy: 0.7812 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4272 - accuracy: 0.7812 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.7830 - val_loss: 0.4965 - val_accuracy: 0.7812\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4271 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7812\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4271 - accuracy: 0.7830 - val_loss: 0.4964 - val_accuracy: 0.7865\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4271 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7865\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4271 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7865\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7865\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.7830 - val_loss: 0.4965 - val_accuracy: 0.7917\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7865\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4270 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7865\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4270 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7865\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7865\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4269 - accuracy: 0.7795 - val_loss: 0.4966 - val_accuracy: 0.7865\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4268 - accuracy: 0.7795 - val_loss: 0.4966 - val_accuracy: 0.7865\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7865\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7865\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4268 - accuracy: 0.7830 - val_loss: 0.4965 - val_accuracy: 0.7865\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4267 - accuracy: 0.7830 - val_loss: 0.4965 - val_accuracy: 0.7865\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.7830 - val_loss: 0.4965 - val_accuracy: 0.7865\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4267 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7812\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4266 - accuracy: 0.7830 - val_loss: 0.4965 - val_accuracy: 0.7865\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4266 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7865\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7917\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7917\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7917\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7847 - val_loss: 0.4966 - val_accuracy: 0.7865\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7795 - val_loss: 0.4966 - val_accuracy: 0.7917\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4264 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7917\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7865\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7917\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7795 - val_loss: 0.4966 - val_accuracy: 0.7917\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7830 - val_loss: 0.4965 - val_accuracy: 0.7917\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7917\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7917\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7830 - val_loss: 0.4965 - val_accuracy: 0.7917\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7830 - val_loss: 0.4965 - val_accuracy: 0.7917\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7917\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7917\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7917\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7917\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7865\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7865\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7830 - val_loss: 0.4965 - val_accuracy: 0.7865\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7865\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4260 - accuracy: 0.7830 - val_loss: 0.4965 - val_accuracy: 0.7865\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7812\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7812\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7830 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7812\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7812\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7812\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7812\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7812\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7812\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7812\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7812\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7812\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7812\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7830 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7847 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7830 - val_loss: 0.4970 - val_accuracy: 0.7812\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7830 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7830 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7847 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7830 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4249 - accuracy: 0.7847 - val_loss: 0.4970 - val_accuracy: 0.7812\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7830 - val_loss: 0.4970 - val_accuracy: 0.7812\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7847 - val_loss: 0.4970 - val_accuracy: 0.7812\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7830 - val_loss: 0.4970 - val_accuracy: 0.7812\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7847 - val_loss: 0.4970 - val_accuracy: 0.7812\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7847 - val_loss: 0.4971 - val_accuracy: 0.7812\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7812\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7847 - val_loss: 0.4970 - val_accuracy: 0.7812\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7847 - val_loss: 0.4970 - val_accuracy: 0.7812\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7847 - val_loss: 0.4970 - val_accuracy: 0.7812\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7812\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4248 - accuracy: 0.7882 - val_loss: 0.4972 - val_accuracy: 0.7812\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7847 - val_loss: 0.4972 - val_accuracy: 0.7812\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7882 - val_loss: 0.4972 - val_accuracy: 0.7812\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7865 - val_loss: 0.4971 - val_accuracy: 0.7760\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7882 - val_loss: 0.4972 - val_accuracy: 0.7760\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7865 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7760\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7882 - val_loss: 0.4972 - val_accuracy: 0.7760\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7882 - val_loss: 0.4972 - val_accuracy: 0.7760\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7865 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7865 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.7865 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7882 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7882 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7882 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7882 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7882 - val_loss: 0.4975 - val_accuracy: 0.7760\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7865 - val_loss: 0.4975 - val_accuracy: 0.7760\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.7882 - val_loss: 0.4976 - val_accuracy: 0.7760\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.4975 - val_accuracy: 0.7760\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.4975 - val_accuracy: 0.7760\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.4975 - val_accuracy: 0.7760\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4237 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.4975 - val_accuracy: 0.7760\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.4975 - val_accuracy: 0.7760\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4237 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4237 - accuracy: 0.7899 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4237 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4237 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4237 - accuracy: 0.7917 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4237 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4236 - accuracy: 0.7917 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4235 - accuracy: 0.7899 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4235 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4236 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4236 - accuracy: 0.7899 - val_loss: 0.4975 - val_accuracy: 0.7760\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4235 - accuracy: 0.7899 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4235 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.7882 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4233 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4231 - accuracy: 0.7899 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.4972 - val_accuracy: 0.7760\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.4972 - val_accuracy: 0.7760\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.4971 - val_accuracy: 0.7760\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.4970 - val_accuracy: 0.7760\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7917 - val_loss: 0.4970 - val_accuracy: 0.7760\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.7899 - val_loss: 0.4968 - val_accuracy: 0.7760\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7899 - val_loss: 0.4968 - val_accuracy: 0.7760\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7917 - val_loss: 0.4968 - val_accuracy: 0.7760\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7917 - val_loss: 0.4968 - val_accuracy: 0.7760\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.7917 - val_loss: 0.4968 - val_accuracy: 0.7760\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7934 - val_loss: 0.4968 - val_accuracy: 0.7760\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7917 - val_loss: 0.4967 - val_accuracy: 0.7760\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7917 - val_loss: 0.4967 - val_accuracy: 0.7760\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7899 - val_loss: 0.4966 - val_accuracy: 0.7760\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7917 - val_loss: 0.4965 - val_accuracy: 0.7760\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7882 - val_loss: 0.4966 - val_accuracy: 0.7760\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.7917 - val_loss: 0.4965 - val_accuracy: 0.7760\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7882 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7882 - val_loss: 0.4965 - val_accuracy: 0.7760\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7899 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7899 - val_loss: 0.4965 - val_accuracy: 0.7760\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7882 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7865 - val_loss: 0.4963 - val_accuracy: 0.7760\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7865 - val_loss: 0.4963 - val_accuracy: 0.7760\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7899 - val_loss: 0.4963 - val_accuracy: 0.7760\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7882 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7865 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7917 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7865 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7865 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7865 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.7865 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7865 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7882 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.7882 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.7865 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.7882 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7865 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.7882 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7882 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7882 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7865 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7882 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7882 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7899 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7882 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7899 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7865 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7882 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4210 - accuracy: 0.7899 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.7899 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.7917 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.7934 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7899 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.7917 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7917 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7899 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7899 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7882 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7882 - val_loss: 0.4955 - val_accuracy: 0.7708\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4209 - accuracy: 0.7882 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4205 - accuracy: 0.7899 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7899 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7917 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4204 - accuracy: 0.7882 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7899 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.7882 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.7899 - val_loss: 0.4955 - val_accuracy: 0.7708\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.7865 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.7899 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.7899 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7882 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.7899 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7882 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7917 - val_loss: 0.4955 - val_accuracy: 0.7708\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7917 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7882 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7882 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7882 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7917 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.7899 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7882 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4197 - accuracy: 0.7917 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4196 - accuracy: 0.7917 - val_loss: 0.4952 - val_accuracy: 0.7708\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7917 - val_loss: 0.4952 - val_accuracy: 0.7708\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.7865 - val_loss: 0.4952 - val_accuracy: 0.7708\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.7899 - val_loss: 0.4952 - val_accuracy: 0.7708\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7899 - val_loss: 0.4952 - val_accuracy: 0.7708\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7899 - val_loss: 0.4951 - val_accuracy: 0.7708\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7899 - val_loss: 0.4951 - val_accuracy: 0.7708\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7882 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7899 - val_loss: 0.4950 - val_accuracy: 0.7708\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.7899 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7917 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7917 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7917 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7917 - val_loss: 0.4948 - val_accuracy: 0.7708\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.7899 - val_loss: 0.4948 - val_accuracy: 0.7708\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.7951 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7882 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7917 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.7882 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4190 - accuracy: 0.7882 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7917 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7899 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.7882 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.7882 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4190 - accuracy: 0.7899 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.7899 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4188 - accuracy: 0.7882 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4187 - accuracy: 0.7899 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.7899 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.7899 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.7917 - val_loss: 0.4945 - val_accuracy: 0.7760\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4186 - accuracy: 0.7899 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4186 - accuracy: 0.7899 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.7917 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4185 - accuracy: 0.7899 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.7882 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.7899 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4183 - accuracy: 0.7899 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4183 - accuracy: 0.7934 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.4182 - accuracy: 0.7899 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.4183 - accuracy: 0.7899 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 0.4182 - accuracy: 0.7934 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.4181 - accuracy: 0.7917 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.4181 - accuracy: 0.7917 - val_loss: 0.4940 - val_accuracy: 0.7812\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4181 - accuracy: 0.7969 - val_loss: 0.4940 - val_accuracy: 0.7812\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4181 - accuracy: 0.7951 - val_loss: 0.4939 - val_accuracy: 0.7812\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.7917 - val_loss: 0.4938 - val_accuracy: 0.7812\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.7899 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.7934 - val_loss: 0.4938 - val_accuracy: 0.7812\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.7917 - val_loss: 0.4938 - val_accuracy: 0.7812\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.7951 - val_loss: 0.4938 - val_accuracy: 0.7812\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.7899 - val_loss: 0.4938 - val_accuracy: 0.7812\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7934 - val_loss: 0.4938 - val_accuracy: 0.7812\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.7917 - val_loss: 0.4938 - val_accuracy: 0.7812\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7812\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7812\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7812\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.7934 - val_loss: 0.4935 - val_accuracy: 0.7812\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.7951 - val_loss: 0.4935 - val_accuracy: 0.7812\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.7951 - val_loss: 0.4935 - val_accuracy: 0.7812\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.7951 - val_loss: 0.4935 - val_accuracy: 0.7812\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.7951 - val_loss: 0.4935 - val_accuracy: 0.7812\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7812\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7812\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.7951 - val_loss: 0.4936 - val_accuracy: 0.7812\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.7951 - val_loss: 0.4936 - val_accuracy: 0.7812\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7812\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.7951 - val_loss: 0.4934 - val_accuracy: 0.7812\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.7951 - val_loss: 0.4934 - val_accuracy: 0.7812\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7951 - val_loss: 0.4933 - val_accuracy: 0.7812\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.7951 - val_loss: 0.4933 - val_accuracy: 0.7812\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7812\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.7951 - val_loss: 0.4934 - val_accuracy: 0.7812\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.7951 - val_loss: 0.4934 - val_accuracy: 0.7812\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.7951 - val_loss: 0.4935 - val_accuracy: 0.7812\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.4933 - val_accuracy: 0.7812\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.7951 - val_loss: 0.4934 - val_accuracy: 0.7812\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4164 - accuracy: 0.7951 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.7951 - val_loss: 0.4935 - val_accuracy: 0.7760\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4164 - accuracy: 0.7951 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.7951 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.7951 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.7951 - val_loss: 0.4931 - val_accuracy: 0.7812\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.7934 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.7969 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.7934 - val_loss: 0.4931 - val_accuracy: 0.7812\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.7934 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.7951 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.7917 - val_loss: 0.4934 - val_accuracy: 0.7812\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.7951 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7812\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.4933 - val_accuracy: 0.7812\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.7951 - val_loss: 0.4933 - val_accuracy: 0.7812\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.7951 - val_loss: 0.4933 - val_accuracy: 0.7812\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.4932 - val_accuracy: 0.7812\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7812\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7812\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.7986 - val_loss: 0.4933 - val_accuracy: 0.7812\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.7917 - val_loss: 0.4933 - val_accuracy: 0.7865\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7865\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7865\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.7986 - val_loss: 0.4933 - val_accuracy: 0.7812\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.7986 - val_loss: 0.4934 - val_accuracy: 0.7865\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.4935 - val_accuracy: 0.7865\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.7951 - val_loss: 0.4936 - val_accuracy: 0.7865\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.4936 - val_accuracy: 0.7865\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.7986 - val_loss: 0.4936 - val_accuracy: 0.7865\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.4936 - val_accuracy: 0.7865\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7865\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.7951 - val_loss: 0.4937 - val_accuracy: 0.7865\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7865\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.7951 - val_loss: 0.4938 - val_accuracy: 0.7865\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.7934 - val_loss: 0.4938 - val_accuracy: 0.7865\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7865\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.7934 - val_loss: 0.4938 - val_accuracy: 0.7865\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7865\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.7951 - val_loss: 0.4938 - val_accuracy: 0.7865\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.7917 - val_loss: 0.4938 - val_accuracy: 0.7865\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.7951 - val_loss: 0.4939 - val_accuracy: 0.7865\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7865\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.7969 - val_loss: 0.4939 - val_accuracy: 0.7865\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.7969 - val_loss: 0.4940 - val_accuracy: 0.7865\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.7934 - val_loss: 0.4941 - val_accuracy: 0.7865\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7865\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7865\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.7969 - val_loss: 0.4942 - val_accuracy: 0.7865\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.7969 - val_loss: 0.4941 - val_accuracy: 0.7865\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.7917 - val_loss: 0.4941 - val_accuracy: 0.7865\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7865\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7865\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8003 - val_loss: 0.4943 - val_accuracy: 0.7865\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7865\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.7969 - val_loss: 0.4942 - val_accuracy: 0.7865\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7865\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.7951 - val_loss: 0.4945 - val_accuracy: 0.7865\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.7969 - val_loss: 0.4945 - val_accuracy: 0.7865\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4138 - accuracy: 0.7969 - val_loss: 0.4944 - val_accuracy: 0.7865\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7865\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7865\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.7969 - val_loss: 0.4944 - val_accuracy: 0.7865\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4136 - accuracy: 0.7934 - val_loss: 0.4945 - val_accuracy: 0.7865\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4135 - accuracy: 0.7969 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.7951 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4134 - accuracy: 0.7934 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4134 - accuracy: 0.7934 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4135 - accuracy: 0.7917 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.7969 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4134 - accuracy: 0.7934 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.7969 - val_loss: 0.4949 - val_accuracy: 0.7865\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.7969 - val_loss: 0.4949 - val_accuracy: 0.7865\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4131 - accuracy: 0.7951 - val_loss: 0.4949 - val_accuracy: 0.7865\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.7951 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.7969 - val_loss: 0.4949 - val_accuracy: 0.7865\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.7934 - val_loss: 0.4950 - val_accuracy: 0.7865\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.7951 - val_loss: 0.4951 - val_accuracy: 0.7865\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4130 - accuracy: 0.7951 - val_loss: 0.4952 - val_accuracy: 0.7865\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4131 - accuracy: 0.7951 - val_loss: 0.4953 - val_accuracy: 0.7865\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4131 - accuracy: 0.7951 - val_loss: 0.4953 - val_accuracy: 0.7865\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4128 - accuracy: 0.7934 - val_loss: 0.4952 - val_accuracy: 0.7865\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4128 - accuracy: 0.7951 - val_loss: 0.4952 - val_accuracy: 0.7812\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4128 - accuracy: 0.7951 - val_loss: 0.4953 - val_accuracy: 0.7812\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4129 - accuracy: 0.7934 - val_loss: 0.4953 - val_accuracy: 0.7812\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.7951 - val_loss: 0.4953 - val_accuracy: 0.7812\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4127 - accuracy: 0.7951 - val_loss: 0.4953 - val_accuracy: 0.7812\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.7951 - val_loss: 0.4954 - val_accuracy: 0.7812\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4127 - accuracy: 0.7934 - val_loss: 0.4955 - val_accuracy: 0.7812\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4126 - accuracy: 0.7986 - val_loss: 0.4956 - val_accuracy: 0.7812\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4124 - accuracy: 0.7986 - val_loss: 0.4956 - val_accuracy: 0.7760\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.7969 - val_loss: 0.4956 - val_accuracy: 0.7812\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.7951 - val_loss: 0.4954 - val_accuracy: 0.7812\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.7986 - val_loss: 0.4955 - val_accuracy: 0.7812\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.7969 - val_loss: 0.4956 - val_accuracy: 0.7760\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.7951 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.7969 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.7969 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.7986 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.7934 - val_loss: 0.4957 - val_accuracy: 0.7760\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.7969 - val_loss: 0.4957 - val_accuracy: 0.7760\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.7969 - val_loss: 0.4957 - val_accuracy: 0.7760\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.7969 - val_loss: 0.4958 - val_accuracy: 0.7760\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.7969 - val_loss: 0.4958 - val_accuracy: 0.7760\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.7969 - val_loss: 0.4958 - val_accuracy: 0.7760\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.7951 - val_loss: 0.4958 - val_accuracy: 0.7760\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.7917 - val_loss: 0.4957 - val_accuracy: 0.7760\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.7969 - val_loss: 0.4958 - val_accuracy: 0.7760\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.7951 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.7951 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.7969 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.7951 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.7951 - val_loss: 0.4962 - val_accuracy: 0.7760\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.7986 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.7951 - val_loss: 0.4962 - val_accuracy: 0.7760\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.7969 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.7934 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.7951 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.7934 - val_loss: 0.4963 - val_accuracy: 0.7760\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.7986 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.7969 - val_loss: 0.4963 - val_accuracy: 0.7760\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.7951 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.7969 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.7951 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.7934 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.7969 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.7969 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.7934 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.7934 - val_loss: 0.4963 - val_accuracy: 0.7760\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.7986 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.7951 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.7969 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.7969 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.7934 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.7969 - val_loss: 0.4966 - val_accuracy: 0.7760\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.7951 - val_loss: 0.4968 - val_accuracy: 0.7760\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.7986 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.7969 - val_loss: 0.4967 - val_accuracy: 0.7760\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.7951 - val_loss: 0.4969 - val_accuracy: 0.7760\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.7951 - val_loss: 0.4968 - val_accuracy: 0.7760\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.7951 - val_loss: 0.4968 - val_accuracy: 0.7760\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.7934 - val_loss: 0.4968 - val_accuracy: 0.7760\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.7951 - val_loss: 0.4968 - val_accuracy: 0.7760\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.7969 - val_loss: 0.4970 - val_accuracy: 0.7760\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.7951 - val_loss: 0.4970 - val_accuracy: 0.7760\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.7951 - val_loss: 0.4969 - val_accuracy: 0.7760\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.7951 - val_loss: 0.4968 - val_accuracy: 0.7760\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.7934 - val_loss: 0.4969 - val_accuracy: 0.7760\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.7951 - val_loss: 0.4968 - val_accuracy: 0.7760\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.7951 - val_loss: 0.4969 - val_accuracy: 0.7760\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.7969 - val_loss: 0.4971 - val_accuracy: 0.7760\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.7951 - val_loss: 0.4971 - val_accuracy: 0.7760\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.7951 - val_loss: 0.4972 - val_accuracy: 0.7760\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.7951 - val_loss: 0.4971 - val_accuracy: 0.7760\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.7934 - val_loss: 0.4971 - val_accuracy: 0.7760\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.7934 - val_loss: 0.4972 - val_accuracy: 0.7760\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.7969 - val_loss: 0.4971 - val_accuracy: 0.7760\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.7969 - val_loss: 0.4972 - val_accuracy: 0.7760\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.7951 - val_loss: 0.4972 - val_accuracy: 0.7760\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.7969 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.7969 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4102 - accuracy: 0.7951 - val_loss: 0.4975 - val_accuracy: 0.7760\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.7969 - val_loss: 0.4977 - val_accuracy: 0.7760\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.7951 - val_loss: 0.4976 - val_accuracy: 0.7760\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.7969 - val_loss: 0.4975 - val_accuracy: 0.7760\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.7969 - val_loss: 0.4977 - val_accuracy: 0.7760\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4100 - accuracy: 0.7969 - val_loss: 0.4977 - val_accuracy: 0.7760\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4101 - accuracy: 0.7951 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.7934 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.7986 - val_loss: 0.4978 - val_accuracy: 0.7760\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.7986 - val_loss: 0.4978 - val_accuracy: 0.7760\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.7969 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.7969 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4101 - accuracy: 0.7969 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.7951 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7969 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.7951 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7969 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.7986 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.7951 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7969 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.7986 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.7951 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7969 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.7969 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.7969 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.7986 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7969 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.7951 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.7951 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4092 - accuracy: 0.7969 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.7951 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4093 - accuracy: 0.7951 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4094 - accuracy: 0.7951 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.7969 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4092 - accuracy: 0.7969 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4094 - accuracy: 0.7969 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4092 - accuracy: 0.7934 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4092 - accuracy: 0.7951 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4093 - accuracy: 0.7934 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4089 - accuracy: 0.7934 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4089 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4089 - accuracy: 0.7934 - val_loss: 0.4987 - val_accuracy: 0.7656\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4091 - accuracy: 0.7951 - val_loss: 0.4989 - val_accuracy: 0.7656\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4089 - accuracy: 0.7951 - val_loss: 0.4989 - val_accuracy: 0.7656\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4089 - accuracy: 0.7969 - val_loss: 0.4990 - val_accuracy: 0.7656\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4088 - accuracy: 0.7934 - val_loss: 0.4989 - val_accuracy: 0.7656\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4089 - accuracy: 0.7969 - val_loss: 0.4988 - val_accuracy: 0.7656\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4088 - accuracy: 0.7969 - val_loss: 0.4989 - val_accuracy: 0.7656\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4088 - accuracy: 0.7951 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4087 - accuracy: 0.7951 - val_loss: 0.4990 - val_accuracy: 0.7656\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4087 - accuracy: 0.7969 - val_loss: 0.4990 - val_accuracy: 0.7656\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4087 - accuracy: 0.7951 - val_loss: 0.4990 - val_accuracy: 0.7656\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4087 - accuracy: 0.7969 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4087 - accuracy: 0.7951 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4087 - accuracy: 0.7951 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4086 - accuracy: 0.7934 - val_loss: 0.4993 - val_accuracy: 0.7656\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4088 - accuracy: 0.7951 - val_loss: 0.4993 - val_accuracy: 0.7656\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4084 - accuracy: 0.7951 - val_loss: 0.4993 - val_accuracy: 0.7656\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.7986 - val_loss: 0.4993 - val_accuracy: 0.7656\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.7986 - val_loss: 0.4993 - val_accuracy: 0.7656\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4085 - accuracy: 0.7917 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4084 - accuracy: 0.7951 - val_loss: 0.4993 - val_accuracy: 0.7656\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4084 - accuracy: 0.7951 - val_loss: 0.4994 - val_accuracy: 0.7656\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4084 - accuracy: 0.7969 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4083 - accuracy: 0.7951 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.7951 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4084 - accuracy: 0.7969 - val_loss: 0.4994 - val_accuracy: 0.7656\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.7951 - val_loss: 0.4993 - val_accuracy: 0.7656\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.7986 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.7934 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.7969 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.7969 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.7951 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4080 - accuracy: 0.7969 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.7934 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.7969 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.7986 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.7951 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.7951 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4079 - accuracy: 0.7986 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.7934 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8003 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.7969 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.7951 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4079 - accuracy: 0.7986 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8003 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.7969 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.7969 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.7986 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.7969 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.7951 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.7969 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.7969 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.7951 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4075 - accuracy: 0.7934 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.7969 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.7951 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4074 - accuracy: 0.8003 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.7969 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.7969 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.7969 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.7986 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.7969 - val_loss: 0.5006 - val_accuracy: 0.7656\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.7934 - val_loss: 0.5006 - val_accuracy: 0.7656\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4074 - accuracy: 0.7986 - val_loss: 0.5007 - val_accuracy: 0.7656\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8003 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8003 - val_loss: 0.5007 - val_accuracy: 0.7656\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.7969 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.7986 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.7986 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8021 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.7969 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8003 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4070 - accuracy: 0.7969 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.7986 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8003 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8021 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8003 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8003 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.7986 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8003 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8003 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.7986 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.7986 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8021 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8038 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8003 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8003 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8038 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8003 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.7986 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8003 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8021 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8003 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8021 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8003 - val_loss: 0.5016 - val_accuracy: 0.7656\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8003 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8003 - val_loss: 0.5016 - val_accuracy: 0.7656\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.7986 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8021 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8003 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.7986 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.7986 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.7986 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8021 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4061 - accuracy: 0.8038 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8003 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8021 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8038 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.8003 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8056 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8038 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.8021 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4059 - accuracy: 0.8003 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8021 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8021 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8038 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8038 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8021 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8003 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8021 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.8038 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4058 - accuracy: 0.8021 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.8021 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4057 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.8038 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4056 - accuracy: 0.8021 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.8021 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4058 - accuracy: 0.8038 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4056 - accuracy: 0.8021 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4056 - accuracy: 0.8021 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4055 - accuracy: 0.8003 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4056 - accuracy: 0.8038 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.8021 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4055 - accuracy: 0.8021 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.8021 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4054 - accuracy: 0.8038 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4053 - accuracy: 0.8021 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4053 - accuracy: 0.8038 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.8038 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4055 - accuracy: 0.8038 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4052 - accuracy: 0.8056 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4053 - accuracy: 0.8021 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4054 - accuracy: 0.8021 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.8038 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4052 - accuracy: 0.8021 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4052 - accuracy: 0.8056 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4053 - accuracy: 0.8038 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.8038 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4052 - accuracy: 0.8038 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4053 - accuracy: 0.8056 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4051 - accuracy: 0.8021 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8038 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4050 - accuracy: 0.8038 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8021 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4050 - accuracy: 0.8038 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4049 - accuracy: 0.8038 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4051 - accuracy: 0.8038 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8021 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.8056 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8038 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8021 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4048 - accuracy: 0.8056 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8038 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4047 - accuracy: 0.8038 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4047 - accuracy: 0.8056 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8038 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8038 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8038 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8038 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8038 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8073 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8056 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8056 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8056 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8021 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8073 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8056 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8021 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8056 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8056 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4042 - accuracy: 0.8056 - val_loss: 0.5048 - val_accuracy: 0.7604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_hist_2.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5QeAMnsy2ok",
        "outputId": "59495ec6-1f8e-4a5e-e2e1-5ffe2ca3610b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(12, 6))\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
        "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
        "ax.legend()\n",
        "ax.set_title('Loss over iterations')\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "ax.plot(range(n), (run_hist_2.history[\"acc\"]),'r.', label=\"Train Acc\")\n",
        "ax.plot(range(n), (run_hist_2.history[\"val_acc\"]),'b.', label=\"Validation Acc\")\n",
        "ax.legend(loc='lower right')\n",
        "ax.set_title('Accuracy over iterations')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "id": "H0Icnxf7ztLL",
        "outputId": "96ff1874-4e85-460e-b86c-7a8f2d5b3997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (200,) and (1500,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-1c920b27a6cb>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrun_hist_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Train Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrun_hist_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \"\"\"\n\u001b[1;32m   1687\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 this, kwargs, ambiguous_fmt_datakey=ambiguous_fmt_datakey)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    505\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (200,) and (1500,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
        "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
        "print('')\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
        "### END SOLUTION"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "2Njew2pHz9ul",
        "outputId": "ec599b8a-db6b-446f-b35a-67ba8ee44d24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Sequential' object has no attribute 'predict_classes'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-e55ee391fe23>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred_class_nn_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred_prob_nn_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy is {:.3f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_class_nn_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'roc-auc is {:.3f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_prob_nn_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f30ZzRoM0BRi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}